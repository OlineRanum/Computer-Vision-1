{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbTUIJVrAaIr"
   },
   "source": [
    "<center><img src=\"http://what-when-how.com/wp-content/uploads/2012/07/tmp26dc139_thumb.png\" width=50% > </center>\n",
    "\n",
    "# <center> Assignment 2: Neighborhood Processing & Filters </center>\n",
    "<center> Computer Vision 1 University of Amsterdam </center>\n",
    "    <center> Due 23:59PM, September 24, 2022 (Amsterdam time) </center>\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufYIQhgROv4X"
   },
   "source": [
    "##(100 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMW9vG1dBifa"
   },
   "source": [
    "## General guidelines\n",
    "Your code and discussion must be completed in this **jupyter notebook** before the deadline by submitting it to the Canvas Lab 2 Assignment. Submit your assignment in a **zip file**, with all the relevant files and images need to run your notebook. Name your zip file as follows:  **StudentID1_StudentID2_StudentID3.zip**\n",
    "For full credit, make sure you follow these guidelines:\n",
    "\n",
    "- Make sure you use the provided python environment. You can create the environment using conda and the provided YAML file using the following command: `conda env create --file=CV1_env.yaml`, then activate it as `conda activate cv1`. Using different packages versions may result in the impossibility to run the submitted code and therefore in the subtraction of points. Below you will find a code cell to check the versions of your packages. \n",
    "- Please express your thoughts concisely. The number of words does not necessarily correlate with how well you understand the concepts.\n",
    "- Answer all given questions.\n",
    "- Try to understand the problem as much as you can. When answering a question, give evidences (qualitative and/or quantitative results, references to papers, figures etc.) to support your arguments. Note that not everything might be explicitly asked for and you are expected to think about what might strengthen you arguments and make your notebook self-contained and complete.\n",
    "- Analyze your results and discuss them, e.g. why algorithm A works better than algorithm B in a certain problem.\n",
    "- Tables and figures must be accompanied by a brief description. Do not forget to add a number, a title, and if applicable name and unit of variables in a table, name and unit of axes and legends in a figure.\n",
    "- Make sure all the code in your notebook runs without errors or bugs before submitting. Code that does not run can result in a lower grade. \n",
    "\n",
    "Late submissions are not allowed. Assignments that are submitted after the strict deadline will not be graded. In case of submission conflicts, TAs’ system clock is taken as reference. We strongly recommend submitting well in advance, to avoid last minute system failure issues.\n",
    "Plagiarism note: Keep in mind that plagiarism (submitted materials which are not your work) is a serious crime and any misconduct shall be punished with the university regulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "nBCvx1UiTn_j"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "error",
     "timestamp": 1663316103937,
     "user": {
      "displayName": "Pieter Pierrot",
      "userId": "05479018623794835299"
     },
     "user_tz": -120
    },
    "id": "DXbuUaRUud2H",
    "outputId": "d644980b-991a-4048-c408-a6827525b962"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "You're not using the provided Python environment!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-709cb3eb5e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make sure you're using the provided environment!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"3.4.2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"You're not using the provided Python environment!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"1.19.5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"You're not using the provided Python environment!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"3.3.4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"You're not using the provided Python environment!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"0.23.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: You're not using the provided Python environment!"
     ]
    }
   ],
   "source": [
    "# Make sure you're using the provided environment!\n",
    "assert cv2.__version__ == \"3.4.2\", \"You're not using the provided Python environment!\"\n",
    "assert np.__version__ == \"1.19.5\", \"You're not using the provided Python environment!\"\n",
    "assert matplotlib.__version__ == \"3.3.4\", \"You're not using the provided Python environment!\"\n",
    "assert sklearn.__version__ == \"0.23.0\"\n",
    "\n",
    "# Proceed to the next cell only if you don't get any error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIIOhzlprt6C"
   },
   "source": [
    "# 1 Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NbweJbQCUny"
   },
   "source": [
    "\n",
    "In this assignment, you will get familiar with fundamentals of neighborhood processing for image processing. These techniques allow for low-level image understanding via extraction of structural patterns such as edges and blobs. Similarly, they find an extensive use in image denoising and higher level image reasoning such as shape recognition. Moreover, neighborhood or block processing is one of the key components of *Convolutional Neural Networks*. Therefore, a good understanding of these\n",
    "procedures will be a stepping stone towards understanding more complex machinery used in computer vision and machine learning.\n",
    "\n",
    "In subsequent sections of this assignment, we will first explain neighborhood processing and introduce low-level filters commonly used to analyze images. After that, we will see how these mathematical concepts relate to practice by working through fundamental tasks such as denoising and segmentation. By the end of this assignment, you will have an overall understanding of the following:\n",
    "* Gaussian and Gabor filters\n",
    "* Edge detection and image denoising\n",
    "* Texture-based image segmentation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "First we need two helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "e1GK_-R4cWPb"
   },
   "outputs": [],
   "source": [
    "# Use this for the last exercise\n",
    "\n",
    "def load_image(image_id: str = 'Polar'):\n",
    "    '''\n",
    "    Loads an image, resizes image with proper resize factor and sets proper color representation\n",
    "    :param image_id: id of an image: Kobi, Polar, Robin0, Robin-2, Cows, SciencePark\n",
    "    :return: image\n",
    "    '''\n",
    "    if image_id == 'Kobi':\n",
    "        img = cv2.imread('./sample_data/sample_data/kobi.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 1.25\n",
    "    elif image_id == 'Polar':\n",
    "        img = cv2.imread('./sample_data/sample_data/polar-bear-hiding.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 1.75\n",
    "    elif image_id == 'Robin0':\n",
    "        img = cv2.imread('./sample_data/sample_data/robin-1.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 2\n",
    "    elif image_id == 'Robin-1':\n",
    "        img = cv2.imread('./sample_data/sample_data/robin-2.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 1.5\n",
    "    elif image_id == 'Cows':\n",
    "        img = cv2.imread('./sample_data/sample_data/cows.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 1.5\n",
    "    elif image_id == 'SciencePark':\n",
    "        img = cv2.imread('./sample_data/sample_data/sciencepark.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        resize_factor = 1.2\n",
    "    else:\n",
    "        raise ValueError('Image not available.')\n",
    "    img = cv2.resize(img, (0, 0), fx=resize_factor, fy=resize_factor)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "d-4o3ljKeJku"
   },
   "outputs": [],
   "source": [
    "def show_image(image, image_title: str = \"Polar\", cmap='gray'):\n",
    "    '''Displays image in grey scale'''\n",
    "    plt.figure()\n",
    "    plt.title(image_title)\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk8dblKYr2z4"
   },
   "source": [
    "# 2 Neighborhood Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wI0keTjXDhS0"
   },
   "source": [
    "\n",
    "Neighborhood processing is simply about looking around a point $I(x, y)$ (i.e. pixel) in the image, $I$, and applying a function, $h(k, l)$, which measures certain properties or relationships between the pixels in that localized window. The function, $h(k, l)$, is generally referred to as the neighborhood operator or local operator. One of the most common forms of a neighborhood operator is a linear filter. Linear filters simply compute the weighted sum of neighboring pixel intensities and assign it to the pixel of interest (output $I_{out}(i, j)$). The filters in which we are interested here are usually represented as a square matrix.\n",
    "\n",
    "---\n",
    "**Hint**: Filters, kernels, weight matrices or masks are interchangeably used in the literature. A kernel is a matrix with which we describe a neighborhood operation. This operation can, for example, be edge detection or smoothing.\n",
    "\n",
    "---\n",
    "\n",
    "Linear filters are shifted over the entire image plane via operators such as correlation ($\\otimes$) and convolution ($\\ast$). Both of these operators are *linear shift-invariant* (LSI) implying that the filters behave the same way over the entire image. Discrete forms of these operators are given in the following:\n",
    "\n",
    "\n",
    "Correlation (1):\n",
    "<center>\n",
    "$\\mathbf{I}_{out} = I \\otimes  \\mathbf{h}\\\\\n",
    " \\mathbf{I}_{out}(i,j) = \\sum_{k,l}  \\mathbf{I}(i+k,j+l) \\mathbf{h}(k,l)$\n",
    "</center>\n",
    "Convolution (2):\n",
    "<center>\n",
    "$    \\mathbf{I}_{out} = \\mathbf{I} \\ast  \\mathbf{h}\\\\\n",
    " \\mathbf{I}_{out}(i,j) = \\sum_{k,l} \\mathbf{I}(i-k,j-l) \\mathbf{h}(k,l)$\n",
    " </center>\n",
    "\n",
    "\n",
    "---\n",
    "The following example illustrates the overall idea of neighborhood processing. The kernel or the mask convolves over the input image. In the case of linear filters, this is simply multiplying each pixel intensity with the corresponding weight in the kernel (see the yellowish $7x7$ window where the kernel is placed). In the example, the kernel is $7x7$ averaging mask. You can see its effect by comparing the red (before filtering) and the green (after filtering) frames.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hQY3W1wLmHv"
   },
   "source": [
    "**Example:**\n",
    "![](https://drive.google.com/uc?export=view&id=1HXt-WTi2Mg-jHYU4tvcKl4R29gi-g1QY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mZ_fs1wWRl8"
   },
   "source": [
    "### Question (10 pts)\n",
    "1.   What is the difference between correlation and convolution operators? How do they treat the signals $\\mathbf{I}$ and $\\mathbf{h}$?\n",
    "2.   Correlation and convolution operators are equivalent when we make an assumption on the form of the mask $\\mathbf{h}$. Can you identify the case?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylaRzZZNLPpU"
   },
   "source": [
    "1. Cross correlation slides the filter $\\mathbf{h}$ along the x-axis of the image $\\mathbf{I}$ in an intuitive way. It starts on the top-left and works its way down along the rows. During this slide it computes a new value for a pixel in $\\mathbf{I}$ beneath the center pixelvalue of $\\mathbf{h}$. It does so based on the surrounding neighbourhood pixels of the image also captured within the filter. This can be a multitude of different filters. Convolution does the same with one significant difference: the filter/mask $\\mathbf{h}$ is rotated 180 degrees / often defined as 'flipped'. Both correlation and convolution are linear and translation invariant. One important property is that convolutions are associative, or in other words, the order of applying filters doesn't matter: $(f \\ast g) \\ast h = f \\ast (g \\ast h)$. This is extremely helpful if we have to apply a sequence of filters to an image, because we can essentially create a combined filter before sliding it over the image, instead of having to slide several filters over the image one at a time. This does not work for correlation.\n",
    "2. If the filter/mask h is point-symmetric then the correlation and convolution operators are the same. This is because flipping the mask has no impact on the mask itself, the values contained within the mask stay within the same order. Thus sliding the filter along the image and computing the values, the kernel's status of flipped or not flipped does not matter. Filters like this would be the Gaussian or Laplacian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJlTkHdTOROo"
   },
   "source": [
    "# 3 Low-level filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Blbzx35sVsf"
   },
   "source": [
    "In this section, you will design common linear filters used in neighborhood processing. We will focus in particular on Gaussian and Gabor filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NhWPur7P1_Q"
   },
   "source": [
    "## 3.1 Gaussian Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oBHyce1saAI"
   },
   "source": [
    "### 3.1.1 1D Gaussian Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyGUgGekPz-a"
   },
   "source": [
    "\n",
    "\n",
    "The 1D  Gaussian filter is defined as follows:\n",
    "<center>\n",
    "$ G_{\\sigma}(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\text{ exp}(-\\frac{x^2}{2\\sigma^2}),$\n",
    "</center>\n",
    "where $\\sigma$ is the variance of the Gaussian. However, such formulation creates an infinitely large convolution kernel. In practice, the kernel is truncated with a `kernel_size` parameter such that $-\\left\\lfloor \\frac{kernel\\_size}{2}\\right\\rfloor \\leq x \\leq \\left\\lfloor \\frac{kernel\\_size}{2} \\right\\rfloor$, where $\\left\\lfloor . \\right\\rfloor$ is the floor operator. As an example, if `kernel_size` equals 3, $x \\in \\{ -1, 0, 1 \\} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2NtMMr9RSVv"
   },
   "source": [
    "### Exercise \n",
    "Now, implement the following *gauss1D* function.\n",
    "\n",
    "**Hint:** \n",
    "Do not forget to normalize your filter.\n",
    "\n",
    "**Note:** You are not allowed to use a Python built-in function provided by *SciPy* or other libraries to compute the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4f5nPDqBdf_",
    "outputId": "8f020ddf-2b1a-45ce-d685-19056676c7eb"
   },
   "outputs": [],
   "source": [
    "def gauss1D(sigma, kernel_size):\n",
    "    G = np.zeros((1, kernel_size))\n",
    "    if kernel_size % 2 == 0:\n",
    "        raise ValueError('kernel_size must be odd, otherwise the filter will not have a center to convolve on')\n",
    "    x_lim = int(np.floor(kernel_size/2))\n",
    "    x = np.linspace(-x_lim, x_lim, kernel_size)    \n",
    "        \n",
    "    # solution\n",
    "    G[0] = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-x**2/(2*sigma**2))\n",
    "\n",
    "    return G / np.sum(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUwwgpFaR5XH"
   },
   "outputs": [],
   "source": [
    "# Run this to test your function:\n",
    "assert np.all(np.round(gauss1D(2,5), 4) == [0.1525, 0.2218, 0.2514, 0.2218, 0.1525]) # check if values are close enough if assert gives error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkT7BklaTUmj"
   },
   "source": [
    "### 3.1.2 2D Gaussian Filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW9S9S-CspJn"
   },
   "source": [
    "\n",
    "One of the most important properties of 2D Gaussian kernels is separability. Therefore, convolving an image with a 2D Gaussian is equivalent to convolving\n",
    "the image twice with a 1D Gaussian filter, once along the x-axis and once along the y-axis **separately**. A 2D Gaussian kernel can then be defined as a product of two 1D Gaussian kernels:\n",
    "<center>\n",
    "$\n",
    "G_{\\sigma}(x, y) = G_{\\sigma}(x) \\times G_{\\sigma}(y)$ *(Eq. A)*\n",
    "\n",
    "$\n",
    " = \\frac{1}{\\sigma^2 2\\pi}\\text{ exp}(-\\frac{x^2 + y^2}{2\\sigma^2})\n",
    " $ *(Eq. B)*\n",
    " </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "762bvpRYTual"
   },
   "source": [
    "### Exercise \n",
    "\n",
    "Implement `gauss2D` function that corresponds to *Eq. A* (not *Eq. B*) and you should make use of `gauss1D`.\n",
    "\n",
    "**Note:** Again, you are not allowed to use a Python built-in function provided by *SciPy* or other libraries to compute the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhfGMWffTtzm",
    "outputId": "62a98d7b-a3d5-4ada-b4c2-ef47982a4dea"
   },
   "outputs": [],
   "source": [
    "def gauss2D(sigma_x, sigma_y, kernel_size):\n",
    "    gauss_x = gauss1D(sigma_x, kernel_size)\n",
    "    gauss_y = gauss1D(sigma_y, kernel_size)\n",
    "    \n",
    "    G = gauss_x.T @ gauss_y\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgMHxPlgVbgQ"
   },
   "outputs": [],
   "source": [
    "# Run this to test your function:\n",
    "assert np.all( np.round(gauss2D(2, 2, 3) , 4) == [[0.1019, 0.1154, 0.1019],\n",
    "       [0.1154, 0.1308, 0.1154],\n",
    "       [0.1019, 0.1154, 0.1019]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2ZB6tEeV_Ls"
   },
   "source": [
    "### Question (5pts)\n",
    "What is the difference between convolving an image with (1) a 2D Gaussian kernel and (2) a 1D Gaussian kernel in the x- and y-direction? Will the result be the same? What is their computational complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gTOdwi4WCyi"
   },
   "source": [
    "There is no difference because of the aforementioned associativity of convolving kernels and images aside from the fact that convolving an image twice with 1d gaussian filters will take longer. The result will therefore be the same. The computational complexity of ---------- ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViVNlHPOa2Jd"
   },
   "source": [
    "### 3.1.3 Gaussian Derivatives\n",
    "So far the Gaussian kernels that we computed are mainly targeted to image enhancement algorithms (e.g. denoising an image). These kernels can also be used for detecting changes in the image intensity pixels. These low-level features can then further be used as building blocks for more complicated tasks like object detection or segmentation.\n",
    "\n",
    "\n",
    "Concretely, the  first order derivative of the 1D Gaussian kernel is given by:\n",
    "\n",
    "<center>\n",
    "$\n",
    "\\frac{d}{dx}G_\\sigma(x)  =\\frac{d}{dx}\\left( \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp(-\\frac{x^2}{2\\sigma^2}) \\right )$\n",
    "\n",
    "$\n",
    " = -\\frac{x}{\\sigma^3\\sqrt{2\\pi}}\\exp(-\\frac{x^2}{2\\sigma^2})$ \n",
    "*(Eq. C)*\n",
    "\n",
    " $\n",
    " = -\\frac{x}{\\sigma^2}G_\\sigma(x)\n",
    " $\n",
    "</center>\n",
    "Similarly, the first order derivative of the 2D Gaussian kernel can be obtained by computing $\\frac{d}{dx}G_\\sigma(x,y)$ and $\\frac{d}{dy}G_\\sigma(x,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMgRkSaSa-7u"
   },
   "source": [
    "#### Question (5pts)\n",
    "A second order derivative of the Gaussian kernel can also be computed. Why\n",
    "is it interesting to design a second order kernel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtsxpaP8bGqC"
   },
   "source": [
    "<b>Answer:</b> A second order can detect local minima and maxima. Local minima and maxima are the indication of where the rate of change in the derivative equals to 0. Corners and edges are such regions. Along a certain line/edge the second derivative will be zero since that is what defines a constant line or edge. However on the sides of that edge the derivative is very large and will rapidly decrease or increase moving up to that edge. A second derivative filter will detect the lack of change in pixel-intensity along an edge and thus display the edge for us. Why is this important? Edges and corners are often the outline of features we want to detect within an image. We often are able to detect an object from its edges and cornes alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtMu-uUgbIHi"
   },
   "source": [
    "## 3.2 Gabor filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G40RQGvgsxAj"
   },
   "source": [
    "Gabor filters fall into the category of linear filters and are widely used for *texture analysis*. The reason why they are a good choice for texture analysis is that they localize well in the frequency spectrum (*optimally* bandlimited) and therefore work as flexible *band-pass* filters.\n",
    "\n",
    "In the following image you can see even (cosine-modulated) and odd parts (sine-modulated) of Gabor filters with fixed-σ Gaussian. You can observe time-domain filters for the modulating sinusoidals of central frequencies, 10, 20, 30, 40 and 50 Hz, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qs5KY3RIL23Z"
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1wv6ZUOfiHMDgg0jW7n5lqkaFiFztjnEo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPyZ-8JveugN"
   },
   "source": [
    "Gabor filters with varying center frequencies are sensitive to different\n",
    "frequency bands. Notice that the neighboring (in the frequency spectrum) filters minimally interfere with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLgAHvd3MBxU"
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1hUQaKE_TwC-9_jMIao1CCxyjembMrUab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1mP6EytbZE2"
   },
   "source": [
    "### 3.2.1 1D Gabor Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0qj4afHtBkK"
   },
   "source": [
    "For the sake of simplicity, we start by studying what a Gabor function is using 1D signals (e.g. speech). The idea will later be generalized to the 2D case, which is suited for our primary interest, images. A Gabor function is a Gaussian function modulated with a complex sinusoidal carrier signal. Let us denote the Gaussian with $x(t)$ and complex sinusoidal with $m(t)$. Then, a Gabor function $g(t)$ can be formulated by:\n",
    "\n",
    "$\n",
    "g(t) = x(t) m(t)   \n",
    "$ *(Eq. D)*\n",
    "\n",
    "where $x(t) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{t^2}{2\\sigma^2}}$ and $m(t)=e^{j 2 \\pi f_c t} = e^{j w_c t}$. $\\sigma$ is the parameter determining the spread of the Gaussian and $w_c$ is the central frequency of the carrier signal.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Hint:**\n",
    "A complex sinusoidal can be represented as follows using the *Euler's formula*:\n",
    "$e^{jwt} = \\cos(wt) + j\\sin(wt)$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Using Euler's formula, we get the following:\n",
    "\\begin{align}\n",
    "    g(t) &= x(t)m(t) \\\\\n",
    "    g(t) &= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{t^2}{2\\sigma^2}} e^{j w_c t} \\\\\n",
    "    g(t) &= \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{t^2}{2\\sigma^2}} [\\cos(w_c t) + j\\sin(w_c t)]\n",
    "\\end{align}\n",
    "We can further arrange the terms and arrive at the following form\n",
    "\\begin{align}\n",
    "    g(t) = g_e(t) + jg_o(t)\n",
    "\\end{align}\n",
    "where $g_e(t)$ and $g_o(t)$ are the even and odd parts arranged orthogonally on the complex plane $\\mathbf{Z}^2$. In practice, one can use either the even or the odd part for filtering purposes (or one can use the complex form).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2fL29EAbaYt"
   },
   "source": [
    "### 3.2.2 2D Gabor Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wor-yxqtLnl"
   },
   "source": [
    "\n",
    "The Gabor filters can also be defined in 2D as well. The main difference lies in the dimensionality of the signals (i.e. carrier and gaussian). A sine wave in 2D is described by two orthogonal spatial frequencies $u_0$ and $v_0$ such that it is given as $s(x,y) = sin(2\\pi(u_0 x + v_0 y))$ where a 2D gaussian is simply $C e^{-(\\frac{(x-x_0)^2}{2\\sigma_x^2}) + \\frac{(y-y_0)^2}{2\\sigma_y^2})}$ with $C$ being a normalizing constant. 2D Gabor function then takes the following forms in the real and complex parts:\n",
    "\n",
    "\\begin{align}\n",
    "    g_{real}(x,y; \\lambda, \\theta, \\psi, \\sigma, \\gamma) = \\exp\\left(-\\frac{x^{\\prime2}+\\gamma^2 y^{\\prime2}}{2\\sigma^2}\\right)\n",
    "\\cos\\left( 2\\pi \\frac{x^{\\prime}}{\\lambda} + \\psi  \\right)                                              \n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "g_{im}(x,y; \\lambda, \\theta, \\psi, \\sigma, \\gamma) &= \\exp\\left(-\\frac{x^{\\prime2}+\\gamma^2 y^{\\prime2}}{2\\sigma^2}\\right)\n",
    "\\sin\\left( 2\\pi \\frac{x^{\\prime}}{\\lambda} + \\psi  \\right)\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\\begin{align}\n",
    "    x^\\prime &= x\\cos\\theta + y\\sin\\theta \\\\\n",
    "    y^\\prime &= -x\\sin\\theta + y\\cos\\theta\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32eQTHQobdGG"
   },
   "source": [
    "#### Question 4 (5pts)\n",
    "Conduct a self-study on the Gabor filters. Explain shortly what the parameters $\\lambda, \\theta, \\psi, \\sigma, \\gamma$ control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfCvFPCltWXs"
   },
   "source": [
    "$\\lambda$ controls the wavelength of the sinusoidal signals. In terms of the filter, it controls the thickness of the bandwidth stripes through which information is passed.\n",
    "\n",
    "$\\theta$ controls the orientation in degrees of that aforementioned stripes. If $\\theta = 0$, then the strip is vertical. Naturally if $\\theta = 90$, the strip's orientation will be horizontal.\n",
    "\n",
    "$\\psi$ controls the phase offset of the sinusoidal signals. It's a time indication for the offset between the sine waves.  \n",
    "\n",
    "$\\sigma$ is the standard deviation of the Gaussian envelope. Higher standard deviation leads to higher bandwidth/more Gabor stripes through which information is passed. Can be seen as controlling the overall size of the Gabor filter's bandwidth.\n",
    "\n",
    "$\\gamma$ controls the flattening (ellipticity) of the Gaussian envelope; so the aspect-ratio of circle-to-ellipse for the Gaussian distribution. In terms of the filter, it controls the length/height of the stripes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIpIVPE4tvE9"
   },
   "source": [
    "### Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QVZG7MciTJn"
   },
   "source": [
    "##### Design array of Gabor Filters\n",
    "\n",
    "Now, you will create a Gabor Filterbank. A filterbank is a collection of filters with varying properties (e.g. {shape, texture}). A Gabor filterbank consists of Gabor filters of distinct orientations and scales. We will use this bank to extract texture information from the input image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTqtQqRqvm6E"
   },
   "source": [
    "Your task is to implement function `createGabor` but to do that you will need some helper functions, which are defined below. Finish the implementation of those and then use them in `createGabor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "jeM6YS5blFZ-"
   },
   "outputs": [],
   "source": [
    "def generateRotationMatrix(theta):\n",
    "  # Returns the rotation matrix. \n",
    "  # Hint: https://en.wikipedia.org/wiki/Rotation_matrix\n",
    "    rotMat = np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]])\n",
    "    return rotMat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "zCXnvzLav1Xg"
   },
   "outputs": [],
   "source": [
    "def createCos(rot_x, lamda, psi):\n",
    "  # Returns the 2D cosine carrier. \n",
    "\n",
    "    cosCarrier = np.cos((2*np.pi)*(rot_x/lamda) + psi)\n",
    "    \n",
    "    # Reshape the vector representation to matrix.\n",
    "    cosCarrier = np.reshape(cosCarrier, (np.int32(np.sqrt(len(cosCarrier))), -1))\n",
    "    return cosCarrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "xGPBzDW_v1c8"
   },
   "outputs": [],
   "source": [
    "def createSin(rot_x, lamda, psi):\n",
    "  # Returns the 2D sine carrier. \n",
    "  \n",
    "    sinCarrier = np.sin((2*np.pi)*(rot_x/lamda) + psi)\n",
    "    \n",
    "    # Reshape the vector representation to matrix.\n",
    "    sinCarrier = np.reshape(sinCarrier, (np.int32(np.sqrt(len(sinCarrier))), -1))\n",
    "    return sinCarrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "pZYsGehtwBUf"
   },
   "outputs": [],
   "source": [
    "def createGauss(rot_x, rot_y, gamma, sigma):\n",
    "  # Returns the 2D Gaussian Envelope. \n",
    "  \n",
    "    gaussEnv = np.exp(-(rot_x**2 + rot_y**2*gamma**2)/(2*sigma**2))\n",
    "    gaussEnv = np.reshape(gaussEnv, (np.int32(np.sqrt(len(gaussEnv))), -1))\n",
    "    \n",
    "    return gaussEnv / np.sum(gaussEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCwJtg9fbgUz"
   },
   "source": [
    "Implement the function `createGabor` using above helper functions and equations for $g_{real} $ and $g_{im}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Lsf82AdMlbOO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in orientation of bandwidth strips by adjusting the angle of rotation theta.\n",
      "Change in size by adjusting the standard deviation sigma of the Gaussian Envelope.\n",
      "Change in ellipticity of the Gaussian Envelope by adjusting Gamma.\n",
      "----\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEV0lEQVR4nO3dP0prWxjG4RUj+AeLYGNhKaQQbKyDrZ04BQtbp6BDcAYOwNoJqLUDECxFxCZaKEJiTn3h6oXL/t5wznmeVnhdbDY/dyGs3mw2awBkLMz7AAB/E9EFCBJdgCDRBQgSXYAg0QUIWvzph0dHR7/V/5NV/PvbwkLN36Wvr6+S3V6vV7Jb5eLiYi4HPjs7K3m3q55/xftS9W7/Ts+gtbrznp6e/uuwL12AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCPrxYsoq/X6/ZHc8Hne+ubW11flma609PDyU7A4Gg5Ld6XRasvunWVpaKtl9enrqfHN9fb3zzdbq3sGKZ9Baa8vLyyW73/GlCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQ9ONtwLPZrOSXrq6uluze3Nx0vnlyctL5ZmutHR8fl+zu7++X7L69vZXszstkMinZ3dzcLNm9vLzsfPPg4KDzzdZaG41GJbvn5+clu8PhsGT3O750AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGC5nIb8MrKSsnu/f1955t7e3udb7ZWc9bWWjs8PCzZfX19Ldmdl+l0WrK7sbFRsnt3d9f5ZtVtwLu7uyW7z8/PJbvb29slu9/xpQsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQT9eTNnr9Up+6cfHR8nucDjsfPP6+rrzzdZqztpa3bOtehfmpd/vl+xWXZ5YddljhYpLNFuru/RzMpmU7H7Hly5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQJDoAgSJLkCQ6AIEiS5AkOgCBIkuQNBcbgN+f38v2d3Z2el88+rqqvPN1mrO2lrds/3TbgNeXPzx1f/fHh8fS3ZHo1HJboXb29uS3c3NzZLd6XRasvsdX7oAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEE1V6L+h6rbN9fW1jrffHl56XyztZqztpa/2ZR/+vz8LNkdDAYluxXG43HJ7tLSUslumi9dgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYCg3mw2m/cZAP4avnQBgkQXIEh0AYJEFyBIdAGCRBcg6BdBYIjWZrTmIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def createGabor(sigma, theta, lamda, psi, gamma):\n",
    "    '''\n",
    "    Creates a complex valued Gabor filter.\n",
    "    myGabor = createGabor(sigma, theta, lamda, psi, gamma) generates Gabor kernels. \n",
    "    :param sigma: Standard deviation of Gaussian envelope.\n",
    "    :param theta: Orientation of the Gaussian envelope. Takes arguments in the range [0, pi/2).\n",
    "    :param lamda: The wavelength for the carriers. The central frequency (w_c) of the carrier signals.\n",
    "    :param psi: Phase offset for the carrier signal, sin(w_c . t + psi).\n",
    "    :param gamma: Controls the aspect ratio of the Gaussian envelope\n",
    "    :return: myGabor - A matrix of size [h,w,2], holding the real and imaginary \n",
    "                        parts of the Gabor in myGabor(:,:,1) and myGabor(:,:,2), respectively.\n",
    "    '''\n",
    "\n",
    "    # Set the aspect ratio.\n",
    "    sigma_x = sigma\n",
    "    sigma_y = float(sigma)/gamma\n",
    "\n",
    "    # Generate a grid\n",
    "    nstds = 3\n",
    "    xmax = max(abs(nstds*sigma_x*np.cos(theta)),abs(nstds*sigma_y*np.sin(theta)))\n",
    "    xmax = np.ceil(max(1,xmax))\n",
    "    ymax = max(abs(nstds*sigma_x*np.sin(theta)),abs(nstds*sigma_y*np.cos(theta)))\n",
    "    ymax = np.ceil(max(1,ymax))\n",
    "\n",
    "    # Make sure that we get square filters. \n",
    "    xmax = max(xmax,ymax)\n",
    "    ymax = max(xmax,ymax)\n",
    "    xmin = -xmax \n",
    "    ymin = -ymax\n",
    "\n",
    "    # Generate a coordinate system in the range [xmin,xmax] and [ymin, ymax]. \n",
    "    [x,y] = np.meshgrid(np.arange(xmin, xmax+1), np.arange(ymin, ymax+1))\n",
    "\n",
    "    # Convert to a 2-by-N matrix where N is the number of pixels in the kernel.\n",
    "    XY = np.concatenate((x.reshape(1, -1), y.reshape(1, -1)), axis=0)\n",
    "\n",
    "    # Compute the rotation of pixels by theta.\n",
    "    # Hint: Create appropriate rotation matrix to compute the rotated pixel coordinates: rot(theta) * XY.\n",
    "    rotMat = generateRotationMatrix(theta)\n",
    "    rot_XY = np.matmul(rotMat, XY)\n",
    "    rot_x = rot_XY[0,:]\n",
    "    rot_y = rot_XY[1,:]\n",
    "\n",
    "\n",
    "    # Create the Gaussian envelope.\n",
    "    # IMPLEMENT the helper function createGauss above.\n",
    "    gaussianEnv = createGauss(rot_x, rot_y, gamma, sigma)\n",
    "\n",
    "    # Create the orthogonal carrier signals.\n",
    "    # IMPLEMENT the helper functions createCos and createSin above.\n",
    "    cosCarrier = createCos(rot_x, lamda, psi)\n",
    "    sinCarrier = createSin(rot_x, lamda, psi)\n",
    "    \n",
    "    # Modulate (multiply) Gaussian envelope with the carriers to compute \n",
    "    # the real and imaginary components of the complex Gabor filter. \n",
    "    myGabor_real = gaussianEnv*cosCarrier  # TODO: modulate gaussianEnv with cosCarrier\n",
    "    myGabor_imaginary = gaussianEnv*sinCarrier  # TODO: modulate gaussianEnv with sinCarrier\n",
    "\n",
    "    # Pack myGabor_real and myGabor_imaginary into myGabor.\n",
    "    h, w = myGabor_real.shape\n",
    "    myGabor = np.zeros((h, w, 2))\n",
    "    myGabor[:,:,0] = myGabor_real\n",
    "    myGabor[:,:,1] = myGabor_imaginary\n",
    "\n",
    "    # Uncomment below lines from \"fig = plt.figure()\" to see how are the gabor filters\n",
    "    # figure\n",
    "    # subplot(121), imshow(myGabor_real,[])\n",
    "    # subplot(122), imshow(myGabor_imaginary, [])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(myGabor_real, cmap='gray')    # Real\n",
    "    ax.axis(\"off\")\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(myGabor_imaginary, cmap='gray')    # Real\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    return myGabor\n",
    "\n",
    "print('Change in orientation of bandwidth strips by adjusting the angle of rotation theta.')\n",
    "createGabor(5, 0, 2, 0, 1)\n",
    "createGabor(5, np.pi/2, 2, 0, 1)\n",
    "print('Change in size by adjusting the standard deviation sigma of the Gaussian Envelope.')\n",
    "createGabor(1, 0, 2, 0, 1)\n",
    "createGabor(5, 0, 2, 0, 1)\n",
    "print('Change in ellipticity of the Gaussian Envelope by adjusting Gamma.')\n",
    "createGabor(5, 0, 2, 0, 1)\n",
    "createGabor(5, 0, 2, 0, 3)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38iQckSqkLjC"
   },
   "source": [
    "#### Question (5pts)\n",
    "Visualize how the parameters $\\theta$, $\\sigma$ and $\\gamma$ affect the filter in spatial domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv13duslkHKe"
   },
   "source": [
    "$\\theta$: $\\theta$ is responsible for the orientation of the stripes. Inputting 0 radians gives the stripes a vertical direction. However $\\frac{\\pi}{2}$ results in the bandwidth stripes having an orientation of an angle with 90 degrees.\n",
    "\n",
    "$\\sigma$: $\\sigma$ changes the size of the overall filter. A higher standard deviation leads to bigger-sized kernel. \n",
    "\n",
    "$\\gamma$: As mentioned in the answer before, $\\gamma$ controls the height of the bandwidth. Not only that, by changing the aspect ratio controlled by $\\gamma$ (especially increasing from 1) it can clearly be seen how the bandwith slowly changes from a circle into an ellipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E41QZ9ZsO6vf"
   },
   "source": [
    "# 4 Applications in image processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXyH4WNDJtSK"
   },
   "source": [
    "## 4.1 Noise in digital images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0vlajJhKojZ"
   },
   "source": [
    "The quality of digital images can be affected in different ways. For example, the\n",
    "acquisition process can be very noisy and with a low-resolution (e.g. some medical\n",
    "imaging modalities only generate a 128x128 image). Noise can also come from the\n",
    "user who set wrong parameters on the digital camera. Consequently, different computer vision algorithms are required to enhance noisy or corrupted images. With the\n",
    "growing amount of photos taken every day, image enhancement has then become a\n",
    "very active area of research.\n",
    "\n",
    "In this section, we only focus on simple algorithms to correct noise coming typically from the sensor of your camera. Many other types of noise or corruption can happen but are out of the scope of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gZn2TPQKtA8"
   },
   "source": [
    "### 4.1.1 Salt-and-pepper noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_vRqsMUK3XV"
   },
   "source": [
    "Noise can also occur with over-exposition causing a ”hot” pixel or with a defective\n",
    "sensor causing a ”dead” pixel. This is called salt-and-pepper noise. Pixels in the\n",
    "image are randomly replaced by either a white or black pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcgoNmEWK7Zk"
   },
   "source": [
    "### 4.1.2 Additive Gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sQFRLM8LA2e"
   },
   "source": [
    "Noise also occurs frequently when the camera heats up. This is called thermal noise\n",
    "and this can be modeled as an additive Gaussian noise. Every pixel in the image\n",
    "has a noise component that corresponds to a random value chosen independently\n",
    "from the same Gaussian probability distribution. The Gaussian distribution has a\n",
    "mean of 0 and its standard deviation corresponds to a parameter.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{rl}\n",
    "\\mathbf{I}^{\\prime}(x) = \\mathbf{I}(x) + \\epsilon \\text{, where } \\epsilon \\sim  \\mathcal{N}(0, \\sigma^2)\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{I}^{\\prime}$ is the noisy image and $\\mathbf{I}$ is the original image without any noise $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8rYWOruVbNB"
   },
   "source": [
    "## 4.2 Image denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4WNOpLWVlnA"
   },
   "source": [
    "### 4.2.1 Quantitative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI5c7v3zVsbD"
   },
   "source": [
    "The peak signal-to-noise ratio (PSNR) is a commonly used metric to quantitatively evaluate the performance of image enhancement algorithms. It is derived from the mean squared error (MSE):\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{rl}\n",
    "MSE = \\frac{1}{m \\cdot n}\\sum\\limits_{x,y}\\Big[\\mathbf{I}(x,y) - \\mathbf{\\hat{I}}(x,y)\\Big]^2\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "where $\\mathbf{I}$ is the original image of size $m\\times n$ and $\\mathbf{\\hat{I}}$ its approximation (i.e. in our case an enhanced corrupted image). The PSNR corresponds to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "PSNR & = 10 \\cdot \\log_{10} \\Big(\\frac{\\mathbf{I}_{max}^2}{MSE}\\Big) \\\\\n",
    " & = 20 \\cdot \\log_{10} \\Big(\\frac{\\mathbf{I}_{max}}{\\sqrt{MSE}}\\Big) \\\\\n",
    " & = 20 \\cdot \\log_{10} \\Big(\\frac{\\mathbf{I}_{max}}{RMSE}\\Big)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "where $\\mathbf{I}_{max}$ is the maximum pixel value of $\\mathbf{I}$ and RMSE is the root of the MSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw8ev7NXYpKj"
   },
   "source": [
    "### 4.2.1.0 Implementing myPSNR\n",
    "\n",
    "In the following section a function is implemented for calculating the PSNR using the above definitions, given an original image and enhanced corrupted image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "AzrSRfzrZVhd"
   },
   "outputs": [],
   "source": [
    "def myPSNR(orig_image, approx_image):\n",
    "    \"\"\" Calculate the Peak Signal to Noise Ratio between an orignal image and an enhanced corruped image\n",
    "    Input:\n",
    "        orig_image: \n",
    "            The orginal image without noise\n",
    "        approx_image: \n",
    "            The artificially enhanced image with noise\n",
    "        \n",
    "    Return:\n",
    "        PSNR: \n",
    "            The peak signal to noise ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    MSE = np.mean((orig_image-approx_image) ** 2)\n",
    "    PSNR = 20*np.log10(orig_image.max()/np.sqrt(MSE))\n",
    "    \n",
    "    return PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPB_GO6QbMzH"
   },
   "source": [
    "## 4.2.1.1 Peak-Signal-to-Noise-Raio\n",
    "\n",
    "The peak-signal-to-noise-ratio yields an expression of the relationship between the maximum value of a signal and a measure of the intensity of the noise distorting the signal. In image processing the PSNR becomes an empirical measure of the effects of various image enhancements algorithms. That is, by taking the ratio between the maximum value of a pixel, and compering it to the MSE calculated between an original image pixel and an artificially enhanced photo. The MSE is an expression of the noise in the signal, as provides a measure of average square difference of the deviation from the original per pixel, in a cumulative manner.\n",
    "\n",
    "When comparing different enhancement methods with the PSNR metric generally a higher value is better, as it would indicate that the peak signal value is large compared to the noise in the image. A low PSNR value would indicate that the difference between the original and the processed image is small compared to the signal strength, which would indicate that less noise is removed by the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rUxvvozbQSf"
   },
   "source": [
    "## 4.2.1.2 PSNR with salt and pepper noise\n",
    "\n",
    "In the following we estimate the PSNR of an image and a variation of the image containing salt and pepper noise, we find that the PSNR value between the two images is 15.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My peak signal to salt and pepper noise ratio for image1 is:  nan\n"
     ]
    }
   ],
   "source": [
    "# Estimating the psnr between original and salt & pepper noise image\n",
    "img_original = cv2.imread('sample_data/sample_data/image1.jpg')\n",
    "img_arr = np.float32(img_original)\n",
    "img_sp = cv2.imread('sample_data/sample_data/image1_saltpepper.jpg')\n",
    "img_sp_arr = np.float32(img_sp)\n",
    "\n",
    "print('My peak signal to salt and pepper noise ratio for image1 is: ', np.round(myPSNR(img_arr, img_sp_arr), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1.3 PSNR with gaussian noise\n",
    "\n",
    "In the following we estimate the PSNR of an image and a variation of the image containing gaussian noise, we find that the PSNR value between the two images is 15.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My peak signal to gaussian noise ratio for image1 is:  nan\n"
     ]
    }
   ],
   "source": [
    "# Estimating the psnr between original and gaussian noise image\n",
    "img_g = cv2.imread('sample_data/sample_data/image1_gaussian.jpg')\n",
    "img_g_arr = np.float32(img_g)\n",
    "\n",
    "print('My peak signal to gaussian noise ratio for image1 is: ', np.round(myPSNR(img_arr, img_g_arr), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-pj7HA9aqAq"
   },
   "source": [
    "## 4.2.2 Neighborhood processing for image denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lpNUDhxayLY"
   },
   "source": [
    "We us the following functions to denoise the image:\n",
    "\n",
    "1. *box filtering*: You can use **cv2.blur** function.\n",
    "2. *median filtering*: You can use **cv2.medianBlur** function.\n",
    "3. *Gaussian filtering*: You must use your **cv2.GaussianBlur** function.\n",
    "\n",
    "### 4.2.2.0 Implementing the denoise function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "ASH65zVMdCsq"
   },
   "outputs": [],
   "source": [
    "def denoise(image, kernel_type, kernel_size = None, sigmaX = 0):\n",
    "    if kernel_type == 'box':\n",
    "        imOut = cv2.blur(image, (kernel_size, kernel_size))\n",
    "    elif kernel_type == 'median':\n",
    "        imOut = cv2.medianBlur(image, kernel_size)\n",
    "    elif kernel_type == 'gaussian':\n",
    "        imOut = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigmaX)\n",
    "    else:\n",
    "        print('Operation Not implemented')\n",
    "    return imOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isKllbE-d1id"
   },
   "source": [
    "### 4.2.2.1\n",
    "\n",
    "We denoise the images image1_saltpepper.jpg and image1_gaussian.jpg with the function denoise by applying the following filters\n",
    "\n",
    "      (a) Box filtering of size: 3x3, 5x5, and 7x7.\n",
    "\n",
    "      (b) Median filtering with size: 3x3, 5x5 and 7x7.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-ef96c01613b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Salt and pepper noise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Gaussian noise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ansel\\anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ansel\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5523\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ansel\\anaconda\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    700\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    701\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 702\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    703\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 216x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtersize = np.array([3,5,7])\n",
    "titles = np.array(['Original', 'Noise', 'Denoise'])\n",
    "\n",
    "\n",
    "def plot_subfig(img, title_, kernel, kernel_size = None, sigma_X = None):\n",
    "    fig, axis = plt.subplots(1, 3, figsize = (15,15))\n",
    "    for i in range(3):\n",
    "        im = denoise(img, kernel, kernel_size[i], sigma_X)\n",
    "        axis[i].imshow(im[:,:,::-1])\n",
    "        axis[i].set_title(' Kernelsize ' + str(kernel_size[i]))\n",
    "        if i == 0:\n",
    "            axis[i].text(0, -60, title_, bbox={'facecolor': 'white', 'pad': 10})\n",
    "    plt.legend()\n",
    "    fig.tight_layout()\n",
    "    #fig.suptitle(title)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize = (3,7))\n",
    "fig, axis = plt.subplots(1, 2, figsize = (15,15))\n",
    "axis[0].set_title('Salt and pepper noise')\n",
    "axis[0].imshow(img_sp)\n",
    "axis[1].set_title('Gaussian noise')\n",
    "axis[1].imshow(img_g)\n",
    "plt.show()\n",
    "\n",
    "# Problem A using box filter\n",
    "plot_subfig(img_sp, 'Denoise on Salt & Pepper using a box kernel', 'box', filtersize)\n",
    "plot_subfig(img_g, 'Denoise on Gaussian noise using a box kernel', 'box', filtersize)\n",
    "\n",
    "# Problem B using median filter\n",
    "plot_subfig(img_sp, 'Denoise on Salt & Pepper using a median kernel', 'median', filtersize)\n",
    "plot_subfig(img_g, 'Denoise on Gaussian noise using a median kernel', 'median', filtersize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih0Xb1WZcaAs"
   },
   "source": [
    "### 4.2.2.2 Estimating PSNR as a function of filter size\n",
    "We present the quantitative results of estimating the PSNR with the function **myPSNR** for all kernels listed in section 4.2.2.1 and present them in table [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'cv::boxFilter'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-2a31ac4c5662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkerneltype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltersize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mim_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_sp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mPSNR_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyPSNR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mkerneltypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msourceimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'salt and pepper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mim_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-9c2bbfc4e151>\u001b[0m in \u001b[0;36mdenoise\u001b[1;34m(image, kernel_type, kernel_size, sigmaX)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdenoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmaX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkernel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'box'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mimOut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mkernel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'median'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimOut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\box_filter.dispatch.cpp:446: error: (-215:Assertion failed) !_src.empty() in function 'cv::boxFilter'\n"
     ]
    }
   ],
   "source": [
    "kerneltype = ['box', 'median']\n",
    "\n",
    "PSNR_values, kerneltypes, sourceimage, size = [], [], [], []\n",
    "\n",
    "\n",
    "for i in kerneltype:\n",
    "    for j in filtersize:\n",
    "        im_kernel = denoise(img_sp, i, j)\n",
    "        PSNR_values.append(np.round(myPSNR(img_arr, im_kernel),2)); kerneltypes.append(i); size.append(j); sourceimage.append('salt and pepper');\n",
    "        im_kernel = denoise(img_g, i, j)\n",
    "        PSNR_values.append(np.round(myPSNR(img_arr, im_kernel),2)); kerneltypes.append(i); size.append(j); sourceimage.append('Gaussian');\n",
    "        \n",
    "\n",
    "    \n",
    "print('-----------------------------------------------------------')\n",
    "print('Table 1: PSNR values for different kernel types and kernel sizes')\n",
    "print('-----------------------------------------------------------')\n",
    "print (\"{:<13} {:<20} {:<10} {:<10}\".format('Kernel type',' Source image',' size',' PSNR Value'))\n",
    "print('-----------------------------------------------------------')\n",
    "for i in range(12):\n",
    "    print (\"{:<14} {:<20} {:<10} {:<10}\".format(kerneltypes[i], sourceimage[i], size[i], PSNR_values[i]))\n",
    "    \n",
    "print('-----------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "maxindex = 7\n",
    "maxindex2 = 6\n",
    "print('The process yielding the highest PSNR (' + str(PSNR_values[maxindex])+ ') value for the ' + sourceimage[maxindex] + ' image is the '+ kerneltypes[maxindex] + ' filter with size ' + str(size[maxindex]) + '.')\n",
    "print('The process yielding the highest PSNR (' + str(PSNR_values[maxindex2])+ ') value for the ' + sourceimage[maxindex2] + ' image is the '+ kerneltypes[maxindex2] + ' filter with size ' + str(size[maxindex2]) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The effect of the filter size on the PSNR**\n",
    "\n",
    "We observe that for the trends for both the salt an pepper noise and the Gaussian noise are the same, and that the PSNR values using the median filters are higher than those of the box filters. For the box filters we see that the highest PSNR value is actually the middle sized 5x5 filter. The performance of the filters relative to their size would be dependent on the complexity of the image under evaluation. In general, one can expect that when using larger filters on more detailed images the effect of averaging over the selected neighborhood produces a less accurate result, in terms of similarity to the original image. That is, more uncorrelated features are combined to estimate the value of the pixel. However, a too small filter runs the risk of allowing for instance a salt noise in the image to be given a larger significance, as its relative weight matters more the smaller the filter is. As such, the filter size relative to the type of image becomes important, and the 5x5 filter appears to yield the highest result in terms of our case study above. \n",
    "\n",
    "The median filters will be less prone to the contribution of outliers, as it discards all extreme values. As we can observe above, the smallest 3x3 filter size performs the best in our case. The performance decreases for both noise types as the filter size increases. This can be understood by considering that the probability that the majority of the pixels within the set of the 9 pixels are representative for the environment is quite large. As such we can expect the 3x3 median filtering to perform quite well. When the filter size increases however, more features are captured and the probability that we are selecting a representative median value for the pixel under consideration decreases. A more detailed description between the filter types follows in the section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UF2XuuyKcbcB"
   },
   "source": [
    "### 4.2.2.3 Median versus Box filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXmdRw3Tcjct"
   },
   "source": [
    "For the salt-and-pepper noise we observe that the median filter performs better than the box filter for all evaluated kernel sizes. That is because the pixels affected by salt-and-pepper noise takes the either the value 0 (black) or 255 (white). When we run a boxfilter we replace each value with the uniformly weighted average of its neighbors. When these extreme values of 0 and 255 is taken into account in the weighted average it contributes to artificially increase or reduce the pixel values in the neighborhood determined by the filter size. As such an artificial distortion away from the original image proportional to the neighborhoods original average value is imposed. The effect would be greater the further away the values of the neighborhood are from the current noise contribution (very light regions will be artificially darkened by the present of pepper, and very dark regions will be artificially brightened by the presence of salt). In a sense, the noise is simply smudged. When taking the median however, the outlier is effectively discarded and will not contribute to the modified pixels value. That is because the values of 255 and 0 never will appear in the middle of a numerical sorting between RGB values, unless they are all at the extremes anyhow. The median should therefore be an expression of the general color tendencies of the neighborhood. \n",
    "\n",
    "When we evaluate kernels for the Gaussian noise source images we observe as well that the median filters perform better than the box filters in terms of the PSNR. In Gaussian noise the noise does not produce an extreme value but a perturbation of the original pixel values according to a Gaussian distribution, as such one can apply the same logic as for the salt and pepper noise, with the expectation that the effects should be somewhat smaller than the extreme salt and pepper noise. In a sense the median kernel methods are more stable and effective against pixels heavily affected by noise, while box filters are more unstable in the sense that they smudge the effect of the error into the neighborhood without completely removing the noise component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoMfg5eccdAX"
   },
   "source": [
    "\n",
    "## Denoising gaussian noise using a gaussian filter \n",
    "\n",
    "For the standard deviation we choose a range of values corresponding to a small, medium and large standard deviation. \n",
    "\n",
    "\n",
    "Even though in theory all pixels needs to be taken into account with the gaussian filter, we can save some computational costs by recognizing that in practice all pixels outside the 3$\\sigma$ range of the mean has a neglishible effect on the estimated pixel value. As such we determine the filter size by taking into account 3$\\sigma$ worth of pixels on each size, leading to an effective formula for the filter size: \n",
    "\n",
    "$$ Filtersize = 2*3*\\sigma = 6\\sigma$$\n",
    "\n",
    "We then roof to the nearest odd integer upwards in order to ensure that we capture all the necessary weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "ZBF3hOk-pnAA",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-49ceac7b960c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mimg_g_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gaussian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmaX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandard_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_g_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0maxis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' Kernel size = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'x'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', Sigma = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandard_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-9c2bbfc4e151>\u001b[0m in \u001b[0;36mdenoise\u001b[1;34m(image, kernel_type, kernel_size, sigmaX)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimOut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mkernel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gaussian'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mimOut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigmaX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Operation Not implemented'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = np.array([3, 7,13,19,31])\n",
    "standard_dev = np.array([0.5,1,2,3,5])\n",
    "\n",
    "arr = np.zeros((len(window_size), 3))\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(1,len(window_size), figsize = (15,15))\n",
    "\n",
    "for i in range(len(window_size)):\n",
    "    img_g_ = denoise(img_g, 'gaussian', kernel_size = window_size[i], sigmaX = standard_dev[i])\n",
    "    axis[i].imshow(img_g_)\n",
    "    axis[i].set_title(' Kernel size = ' + str(window_size[i]) + 'x' + str(window_size[i]) + ', Sigma = ' + str(standard_dev[i]))\n",
    "    PSNR = myPSNR(img_arr, img_g_)\n",
    "    arr[i,:] = np.array([window_size[i],standard_dev[i],PSNR])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "p = ax.scatter(arr[:,0], arr[:,1], c=arr[:,2], s=40, label = 'PSNR')\n",
    "plt.xlabel('Kernel Size')\n",
    "plt.ylabel('$\\sigma^2$ Standard deviation for a gaussian denoise filter')\n",
    "plt.title('PSNR($\\sigma^2$, Kernel Size)')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "plt.colorbar(p)\n",
    "\n",
    "argmax = np.argmax(arr[:,2])\n",
    "maxvalue = arr[argmax,:]\n",
    "\n",
    "print('The maximum calculated PSNR is ' + str(np.round(maxvalue[2],2)) + ' which corresponds to a kernel size of ' + str(int(maxvalue[0]))+' x ' + str(int(maxvalue[0]))+' and a standard deviation of ' + str(maxvalue[1]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbhpdDM9ceii"
   },
   "source": [
    "\n",
    "5.   What is the effect of the standard deviation on the PSNR? Report the results (in a table) and discuss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Table 2: PSNR values for a Gaussian kernel and various kernel sizes\n",
      "-----------------------------------------------------------\n",
      "size          Standard Deviation    PSNR Value\n",
      "-----------------------------------------------------------\n",
      "3              0.5                  0.0       \n",
      "7              1.0                  0.0       \n",
      "13             2.0                  0.0       \n",
      "19             3.0                  0.0       \n",
      "31             5.0                  0.0       \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Table 2: PSNR values for a Gaussian kernel and various kernel sizes')\n",
    "print('-----------------------------------------------------------')\n",
    "print (\"{:<13} {:<20} {:<10}\".format('size', 'Standard Deviation' ,' PSNR Value'))\n",
    "print('-----------------------------------------------------------')\n",
    "for i in range(len(standard_dev)):\n",
    "    print (\"{:<14} {:<20} {:<10}\".format(window_size[i], standard_dev[i], np.round(arr[i,2],2)))\n",
    "    \n",
    "print('-----------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDaSrQvXclwD"
   },
   "source": [
    "A Gaussian filter is a weighted average filter who is weights take the shape of a Gaussian distribution. For the quantized filter sigma determines the concentration of the weights across the filter. In the same sense that a Gaussian curve with a small STD is a slim and centralized curve, a small sigma for the filter indicates that the majority of the weights are positioned in the center of the filter with a steep falloff rate. A large sigma would indicate a wider distribution of weights across the filter, and the filter will take a more similar form to a box filter. The larger the standard deviation, the more generalizing the outcome, and similarly the small the standard deviation is the more details are captured in the blurring process. \n",
    "\n",
    "Table 2 presents an overview over the PSNR values derived using different kernels and standard deviation pairs. We can see that the PSNR value peaks at a filter size of 7x7 with a standard deviation at 1. As propositioned above we can understand this by the tendency of larger sigma values to over generalize and erase the details of a photo, which here appears to be increasingly occurring for standard deviations larger than 1. However, a two small filter size and standard deviation might be unable so sufficiently smoothen out the error, by having a large concentration of weights centered on the error pixel value itself.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7ZZvTGxcfp5"
   },
   "source": [
    "### 4.2.2.6 The difference among median filtering, box filtering & Gaussian filtering \n",
    "\n",
    "\n",
    "The median, box and Gaussian filtering processes have several similarities and differences. Median filtering corrects a pixel value by looking at the sorted numerical value in the range of a neighborhood and replacing the pixel current pixel with the median value of the range taken from the input image. As such, a large peak in error of a singular pixel or outliers in the neighborhood is easily removed in order to enhance the image quality, instead the pixel becomes an expression of the median color tendencies in its surroundings. A box filter transforms a pixel value into the average value of the pixels in the input image within its neighborhood. In this sense the new pixel becomes a low pass filter with the property of using equal weights.\n",
    "The Gaussian filtering is based on the convolving of an image with a Gaussian function, and is somewhat similar to the box filtering, except that the kernel it uses represents the shape of a Gaussian. The standard deviation controls how quickly the weights fall of from the central kernel component, and as such the variation around the mean value. The larger the sigma value the larger the variation across the filter. As such, the Gaussian filter is a low pass filter that discards high frequency components, such as the ones found on edges creating a smoothing effect. When evaluating Gaussian filters one has to take into account the combination of choosing a standard deviation with the filter size. \n",
    "\n",
    "Even though methods can appear to yield similar values in terms of the PSNR, the macroscopic effects they produce may differ vastly when observed by a person. The selection and weighting procedures vary - while the box and the Gaussian filter takes weighted averages they produce more rapidly a blurred outcome, as lines and edges are smoothened out. The median filters however are more successful in removing noise while simultaneously producing a more clear picture, given that it is not in effect averaging out the pixel values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9xrXuV7cmS1"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELQH1DgffAfX"
   },
   "source": [
    "## 4.3 Edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtpvRJaQfHN6"
   },
   "source": [
    "Edges appear when there is a sharp change in brightness. In an image this usually corresponds to the boundaries of an object. Edge detection is a fundamental task used in many computer vision applications. One of them is road detection in autonomous driving, which is used for determining the vehicle trajectory.\n",
    "\n",
    "Many different techniques exist for computing the edges. In this section, we will focus on filters that extract the gradient of the image. We will try to detect the road in an still image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpC_NGfufN3R"
   },
   "source": [
    "### 4.3.1 First-order derivative filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8umfWKDIfZD3"
   },
   "source": [
    "**Sobel** kernels approximate the first derivative of a Gaussian filter. Below are the Sobel kernels used in the $x$ and $y$ directions.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{rl}\n",
    "G_x = \\begin{bmatrix} +1 & 0 & -1 \\\\ +2 & 0 & -2 \\\\ +1 & 0 & -1 \\end{bmatrix} * \\mathbf{I}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{rl}\n",
    "G_y = \\begin{bmatrix} +1 & +2 & +1 \\\\ 0 & 0 & 0 \\\\ -1 & -2 & -1 \\end{bmatrix} * \\mathbf{I}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "The gradient magnitude is defined as the square root of the sum of the squares of the horizontal ($G_x$) and the vertical ($G_y$) components of the gradient of an image, such that: \n",
    "\\begin{equation}\n",
    "G =\\sqrt {{G_x}^2+{G_y}^2}\n",
    "\\end{equation}\n",
    "The gradient direction is calculated as follows:\n",
    "\\begin{equation}\n",
    "\\theta= \\tan ^{ - 1}{\\frac{G_y}{G_x}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7bhn7zvh6bh"
   },
   "source": [
    "### Question (10 pts)\n",
    "Using your implemented function **compute_gradient** on image2.jpg, display the following figures:\n",
    "\n",
    "  1. The gradient of the image in the x-direction.\n",
    "\n",
    "  2. The gradient of the image in the y-direction.\n",
    "\n",
    "  3. The gradient magnitude of each pixel.\n",
    "\n",
    "  4. The gradient direction of each pixel.\n",
    "\n",
    "Discuss what kind of information every image conveys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "xrmc2tRlgtcp"
   },
   "outputs": [],
   "source": [
    "def compute_gradient(image):\n",
    "    Sobel_x = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "    Sobel_y = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "    \n",
    "    Gx = scipy.signal.convolve2d(image,Sobel_x)\n",
    "    Gy = scipy.signal.convolve2d(image,Sobel_y)\n",
    "    \n",
    "    im_magnitude = np.sqrt(np.square(Gx)+np.square(Gy))\n",
    "    im_direction = np.arctan(np.divide(Gy,Gx))\n",
    "    \n",
    "    return Gx, Gy, im_magnitude,im_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-105fdb90d7de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./sample_data/sample_data/image2.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mGx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_magnitude\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_direction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "import os\n",
    "cd = './sample_data/sample_data/image2.jpg'\n",
    "image = cv2.imread(cd)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "[Gx,Gy,im_magnitude,im_direction] = compute_gradient(image)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(Gx,cmap='gray')\n",
    "plt.title('Gradient in x-direction')\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(Gy,cmap='gray')\n",
    "plt.title('Gradient in y-direction')\n",
    "plt.axis('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(im_magnitude)\n",
    "plt.title('Gradient magnitude')\n",
    "plt.axis('off')\n",
    "plt.subplot(224)\n",
    "plt.imshow(im_direction)\n",
    "plt.title('Gradient direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Cy-LVfgjg4"
   },
   "source": [
    "Calculating the gradient in the x-direction will reveal vertical edges, as a large change in gradient in the x-direction means that the difference in pixel value between the left and right pixels are large and this is a scenario that could be found when there is a vertical edge. \n",
    "\n",
    "The gradient in the y-direction will reveal horizontal edges, as the gradient in this direction will be large if there is a large difference between the top and bottom pixels. \n",
    "\n",
    "The output of the images of the gradients in the x and y direction also corroborates the explanation above, as in the image where the gradient in the x-direction, the trunk of the trees are very prominent due to it having a shape with vertical lines, whilst in the image of the gradient in the y-direction the trunks of the trees can not be seen. \n",
    "\n",
    "The magnitude and direction of the gradient can be both used to describe the direction of the edge detected, as the magnitude is a combination of the contribution in both the x-direction gradient and the y-direction gradient, and the direction shows the signifcance of each contribution, for instance an angle of 0 means that all the contribution comes from the gradient in the x-direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq-ynXBQgkQ3"
   },
   "source": [
    "###Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx_8_LPDgoeG"
   },
   "source": [
    "Implement **compute_gradient**\n",
    "\n",
    "**Note:** \n",
    "You are not allowed to use the Python built-in functions for computing gradient. But for doing 2D convolution, you can benefit from *scipy.signal.convolve2d* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWWN7NEzi1Ly"
   },
   "source": [
    "### 4.3.2 Second-order derivative filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rZSE3toi6iP"
   },
   "source": [
    "Compared to the Sobel filter, a Laplacian of Gaussian (LoG) relies on the second derivative of a Gaussian filter. Hence, it will focus on large gradients in the image. A LoG can be computed by the following three methods:\n",
    "\n",
    "\n",
    "\n",
    "*   method 1: Smoothing the image with a Gaussian kernel (kernel size of 5 and standard deviation of 0.5), then taking the Laplacian of the smoothed image (i.e. second derivative).\n",
    "*   method 2: Convolving the image directly with a LoG kernel (kernel size of 5 and standard deviation of 0.5).\n",
    "\n",
    "*   method 3: Taking the Difference of two Gaussians (DoG) computed at different scales $\\sigma_1$ and $\\sigma_2$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFkZWEA7EmZB"
   },
   "source": [
    "###Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5hqL-iUEnTz"
   },
   "source": [
    "Implement **compute_LoG**\n",
    "\n",
    "The function should be able to apply any of the above mentioned methods depending on the value passed to the parameter *LOG_type*\n",
    "\n",
    "**Note:** \n",
    "You are not allowed to use the Python built-in functions for computing LOG kernels. But for doing 2D convolution, you can benefit from *scipy.signal.convolve2d* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "7oOpjcpnFDKY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scale(image):\n",
    "    min_pixel = -np.amin(image)\n",
    "    image = image+min_pixel\n",
    "    max_pixel = np.amax(image)\n",
    "    image = (image/max_pixel)\n",
    "    image = image*255\n",
    "    image = image.astype(int)\n",
    "    return image\n",
    "    \n",
    "def compute_LoG(image, LOG_type):\n",
    "    sigma = 0.5\n",
    "    k = 0.86\n",
    "    gaussian_kernel = gauss2D(sigma,sigma,5)\n",
    "    laplacian_kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "    if LOG_type == 1:\n",
    "        #method 1 \n",
    "\n",
    "        imOut = scipy.signal.convolve2d(image,gaussian_kernel)\n",
    "        imOut = scipy.signal.convolve2d(image,laplacian_kernel)\n",
    "\n",
    "\n",
    "    elif LOG_type == 2:\n",
    "          #method 2\n",
    "        log_kernel = scipy.signal.convolve2d(gaussian_kernel,laplacian_kernel)\n",
    "        print(log_kernel.shape)\n",
    "        imOut = scipy.signal.convolve2d(image,log_kernel)\n",
    "\n",
    "    elif LOG_type == 3:\n",
    "        im1 = scipy.signal.convolve2d(image,gaussian_kernel)\n",
    "        gaussian_kernel_2 = gauss2D(sigma*k,sigma*5,5)\n",
    "        im2 = scipy.signal.convolve2d(image,gaussian_kernel_2) \n",
    "    \n",
    "        imOut = im2 - im1\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    return imOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5GSV9v2FMHA"
   },
   "source": [
    "### Questions (10 pts)\n",
    "\n",
    "1.   Test your function using image2.jpg and visualize your results using the three methods.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-e29d6d5fc7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./sample_data/sample_data/image2.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cd = './sample_data/sample_data/image2.jpg'\n",
    "image = cv2.imread(cd)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_list = [] \n",
    "for i in range(3):\n",
    "    imOut = compute_LoG(image,i+1)\n",
    "    imOut = scale(imOut)\n",
    "    image_list.append(imOut)\n",
    "\n",
    "plt.figure(figsize=(20, 18), dpi=80)\n",
    "plt.subplot(221)\n",
    "plt.imshow(np.ascontiguousarray(image_list[0]),cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Method 1')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(image_list[1],cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Method 2')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(image_list[2],cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('Method 3')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnXZnTGqqnVw"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DF4d8ZCgPgd"
   },
   "source": [
    "\n",
    "2.   Discuss the difference between applying the three methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1kbBulkgWsn"
   },
   "source": [
    "Since convolution is associative, the order of convolution with different filters should not effect the final output of the image, hence the output between the first two methods should be the same. One difference between the output of the two methods is the dimensions, since the filters are different sized, the final output of the image will also be a different size if no additional padding is added. Furthermore, the amount of computation is different between the first two methods, since the amount of computation of a convulation with a w x w filter scales with $w^2$. In the first method, we convolute 2, 2d gaussian kernel of dimension (3 x 3), and the second method involves in a convolution of a filter with dimensions of (7x7), hence the first method is more computationally efficient. The third method is an approximation of the LoG, by subtracting two images convoluted with different standard deviation of the gaussian kernel. This allows us to change the parameters to select the frequency in which we want the image to display. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDOR_Ee_gQy5"
   },
   "source": [
    "\n",
    "3.   In the first method, why is it important to convolve an image with a Gaussian before convolving with a Laplacian?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfas5xWPgXSb"
   },
   "source": [
    "The calculation of the second derivative (Laplacian) is very sensitive to noise, hence if the image contains lots of noise the calculation could lead to erronous/noisy result. By applying the Gaussian filter before hand, the high frequency components are reduced, making the convolutation with the Laplacian less noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mONfgLCbgR-o"
   },
   "source": [
    "4.   In the third method, what is the best ratio between $\\sigma_1$ and $\\sigma_2$ to achieve the best approximation of the LoG? What is the purpose of having 2 standard deviations?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzCa85MtgYDM"
   },
   "source": [
    "The two different standard deviation to calculate the Difference of Gaussians, can be seen as the range of frequency of the image in which we want to filter, therefore the Difference of Gaussians can be seen as a bandpass filter. To illustrate this effect, the equation for the application of Difference of Gaussian is shown below. \n",
    "\n",
    "$$\\Gamma_{\\sigma_1,\\sigma_2}(x) = I * (\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}-\\frac{1}{2\\pi K^2\\sigma^2}e^{-\\frac{x^2+y^2}{2K^2\\sigma^2}})$$\n",
    "\n",
    "Where K is the ratio between $\\sigma_1$ and $\\sigma_2$. \n",
    "\n",
    "Gaussian filters are smoothing filters, where the larger the $\\sigma$, the higher frequencies from the image will be removed, hence $\\sigma_1$ can be seen as the parameters removing the high frequency. Since the second gaussian term is being subtracted from the first term, $\\sigma_2$ has the opposite effect of $\\sigma_1$, where frequencies above $\\sigma_2$ are retained. Combining these terms essentially means that any frequencies between the range of $\\sigma_1$ and $\\sigma_2$ are kept, and any outside this range are removed.\n",
    "\n",
    "To find the optimal ratio (K) of $\\sigma_1$ and $\\sigma_2$, a range of K will be simulated in the calculation of the Difference of Gaussian, and the mean-squared error of the output from the Difference of Gaussian and the Laplacian of Gaussian will be calculated. The K resulting in the lowest error will be the best ratio for $\\frac{\\sigma_1}{\\sigma_2}$. As shown below, it was found that a K of 0.86 will result in the best approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABIJUlEQVR4nO2dd3gdxbn/P696s5olN3X3KjdhG5sOJrRgeicmISEkIZeE5HJDIJB2E+4vpJCQQEiooYUYQjXBNGPAFFe5F7mq2LKK1bs0vz9mhQ+y+jnSKXo/z7PPObs7Z+bdPbP7nZl3ihhjUBRFURRPEORtAxRFUZTAQUVFURRF8RgqKoqiKIrHUFFRFEVRPIaKiqIoiuIxVFQURVEUjxHwoiIiD4nITwYprZNFZOdgpNUh3UkiskFEqkXkvwY7/b4iIukiUiMiwd2EMSIyfjDt6iv+dt+7Q0S+JSLFzv8y3Nv2KH6MMcatDVgJHAXC3Y3L3zbAAON9wI5HgN/38B99vR/xhgF3AzuBWqAQeAM428P2H2dfX+4t8FOgGah2tl3AA8DoPtggwC3AJqAOOOzYdVV/7/sA/+eZzj0KcbH/T8AOIKWPcYUC9cDMbsLMAtY592YdMKubsInAP4FSZ3saiHU5Hwz8Eihy/q8NQLzL+e87978SeNT13QLUdNhagT+5nI8C/uKkWwms6vAf/x9Q5mz/DxDnXHoncRvgBy6/TwaeASqcd97TLufCHVurHNtvczl3chdxX+oSZizwmnM/SoH/1+F+/hv7DB4ArnE5d22HeOucuOe6hJkDrHLOFwO3dshH7zm/2wGc5XLuxx3irgfagKRu85MHMnYrUA5cPoAPUIg3Htxe2OUrovI23YgG/ReVV7AvkPlYgQkDzgHu97D9x9nXl3uLFZWnnO+hwDRgGfal1Sthwb6Q84DFQCT2xXcS8Hh/73sP6bmVp3ERFezL8mFgMzCyH3Gl4iJQnZwPc15m33denv/l7Id1Ef4vwAogFohz7tPvXM7/EngXyHBsnw5EOOe+5Lz4pgEJTt64t4t0op2X3Skux54CnsMKQDBffLl+E1tASgVSgG3AzV3EneW82zJdjn0A/M65plBgtsu5XzvnE4ApWGE5p4u4T8OKR7TL/d0D3OZcUwSQ7RL+WaxIxzh5shKY1kXcNzhxtYtlEnAEKz7hwDBgikv4j51rigQuxQpmcjfP2bs95ic3M/bdwEeOUa91OPc48BDwlnMD3wcyXM4bJ3PuxSrzb4AglxvzEfB7rGD90vkjnwRKsBn6LmzzXSJQAHzZ+W0M9uXwFRc7funyZxYAtzs3+hBwEXAetnRbDvzYxcZ5zk2vcMI+gPMgYZXfYEsPNcCV7fG7/H4K9qGoALYCF3a4P38GXnfuz6fAuG7u9YVOHBVOnFOc4+9iM3+DY8fETn67kk5efs79u8u5n0ec+xvnnDsLWzJJ7UN++BlOqRH70NXilLiwmbYB+9BlcuyF+L8d7H/AJX/cDOzGlgr/jPOgdJHZn+pwLBjIBe5zOfYNJ2+UYwVzjHN8omNDTh+u9bj7Thd5tKs83UmcXea3TsK238Nw4AlgPTC8G3vDgT9ghbbI+R7u2F3rxFVDJy8N4GxsLVVcjh2k65fmG8C3Xfa/A7zpfE9w0uk0r2NrAr9y2T8TONxF2KXY90f7C3QStqYQ20X41cBNLvs3Ap90EfYe4L0O92A/ENxF+EJcavDAL4Dnugj7GPCYy/5NwAddhI0GmnB5roF/0LXQvgfc47L/K+AfXYSdCDQCw1yOfUAnQosV/z3A0h6fjd4+RF0YlQd8G5iLbX4Y6XLucezL8hQn894PfOhy3jg3IBFb9dyF8+LDPoAtwHexL55I7MP6MlZpM53wN7r84YeBEcDfgGUd7HAVlRasGIZiXzIlTkYehi0dNQBjnfBzgQWODZnAduB7Ha5hvMv+aTii4sSfh61ChgFnOPdjkotd5dgXSQi2iaCrTNj+4C924r3dibtd4FbSj5oK8DUnnrFYMX6xPQMC9wIr+5gfzgA2O98XOpnwU5dzuc73TL7YdHOcfc7514B4J3+U0PVL7Kd0EBXn+M87pF+KbQoIx9ZMVjnnbgb29yP/f8Fuus+jN9AhT3cSX7f5rUPY9nu4DFsgie/B1p8Dn2CfkWTsC/YXnf0fnfz2+8AbHY69hkvTUIdzFwDLsQKSgBXg7znnTsGK5v9gn9ldwHdcfpsLXOmyn+TYdpxgOvH+1GX/K9ja2u+d/3ozX2xiqgTmu+znANVdXMMe4AaX/buBN7E1oTJgDXCqcy7BsdH1/XcZzrPQId4o7HvgNJdjj2KF4g3H7pXADOfcbKC+Qxw/BF7tJO4MbEEnq8M9ut/5v48ArwLpzrmLge0d4ngAl+ZEl+OnYAsDMT09F/121IvISc5FPG+MWef8Cdd0CPa6MWaVMaYRuBM4UUTSXM7/nzGm3BhzEFtyutrlXJEx5k/GmBasUl8J3GGMqTbG7Ad+C1wPYIxZAfwLeAc4H1vN7Ypm4H+NMc3YanIStjmn2hizFVsbyHbiXWeM+cQY0+Kk+Vfg1F7eogXYF/W9xpgmY8y72AfR9RpfNMZ85lzj09h26864Ensv33Lsvg8rtAt7aUtXXIttlthrjKkB7gCuEpEQ7H053B5QRBJFpEJEKkWkoYv4PgYmOI7eU7A+hxQRicHet/f7aN+9xpgKJ3+8R9f3pyuKsIUWsNf6qDFmvZMf78Dmx0w6XCuAiBQ419sgIhk9JeR0Ougyj7bb056njTH1HePoZ347G/sMVvQQ7lrg58aYI8aYEmyt8voeftNODPaF7EolVjw7Yz22INXuu2jFNomBbXqKwxaUsrAv35+KyOIu0mr//oW0RCQde2+ecDmcim1KqwTGYH1kT4jIlG7ijhER6RD3ycBIrGC7xn02Nh+Owv63L4tIkhOvq63t3zu7P5dihcP1WUgFrgL+6Nj9uhN3WCc2dxf3V7A1nn0d4l4K3IotnO3DNqfRx7iXYgvrNZ2c+wLu9P5aCqwwxpQ6+884x1zJb//iGFOOvWnHncc2F3R1Lolj7bqu4VNc9h/GZqjHjDFl3dhdZoxpdb63P9jFLufrcTKJiEwUkddE5LCIVGGrkkndxO3KGCDfGNPWjc2uL7I6jmXOzuL6/NqdOPM7xNUfvhCv8z0E+0CVAaNd0iw3xsRjS9PhnUXmvCjXYh/2U7APzmpgEf0Tld7en65IweY5OP4e1mCvMYUO1+qcT8X+1+HYqn9P9CaP5tMN/cxvFwD3iMjXegjX2X89pouwHanB+kdcicWWuDvjX9gayDAn3B5sCR+OPXM/N8bUG2M2YQt353WRVvv3jml9Bdvy4foCrccWGn/pFOTex4rA2d3EXWOcorgLS4EXOrxA67G12UeMMc3GmOew/+ciJ15XW9u/d3Z/lgJPdkiz3rmWN4wxTdhC43Bs83lf7v1X+KLItsf9b2PMGmNMA7YwsVBE4nobt4hEApd3Enen9EtUnESuAE51HoDD2CryTBGZ6RI0zeU3MdhSY1Fn57Eq6nrO9aaXYjNLRofwhU7cwdhS3ZPAtzzYFfVBbI+ICcaYWGxTVm9eMGCvJU1EXO/x5zb3kSJcrt0pWaX1M64u48Xa14IV2XeAE0QktY9xvo9tapqNbSJ4H+t8nYf1Q3VGx4fabZz7/mVsGzEcfw+jsQ9uIbaJIFVEctxIsts86tDTdfYnv63GXuf9ItKxpcCVzv7roi7CdmQrkN2hRJ/tHO+MmcBfjTG1zov5IY6Jxibns6t7sdX5vWtcxZ0UFDt7gW6iezqL+wvX0M0LdFNXNhtjjmJ9YD3FnYZtIn+yt3FjxTlERCb0EPcibCHBtXbVWdzt38WJY6yIuNZMjosbuARbOFvZhY1foL81lYuwVdqp2CaJWVhV/QD7Z7dznoic5FTjfoFt33Ytrf23iCQ4N/tWbA+H43BqFs8D/ysiw5zmiNs4Vvr5sfP5NazKP9ndGIg+MAzr+KsRkcnAtzqcL8b6IzrjU6wf5HYRCRWR07AP/3P9sON54HwROVNEQoEfYB1sq/sQR4iIRLhsodhq8PdFJMsR/V8B/3SaX1ZgS3kvich8EQlzfrOgh3Tex+aBbU6payXwdWCf0+zSGd3dxz7h3Osp2Gsbhe1EArYm/VURmSUi4dhr/dQYs98YsxNbKHlORBaLSKSTf3rdvNiLPNobespvXaX9PvbBf1hELusi2LPAXSKS7DTZ3N0H21Zin/f/EpFwEbnFOf5uF+HXAF937mMk1hGd69i6B/ueuNOJawq22fA157dPAjeKyFQRScB2dnjcNXIRWYitAf6rQ7qrsB0I7hCREOdFexrWF9Ie920ikiIiY7DP0eMd4rgY6/N5r8PxfwMJIrJURIKd+5yC7XzRHvddzvtsMtZf2zHu64HVzj1w5SlggYic5eS772ELKduNMbVYX+fPRSTauaYlWB+MK+21q441mMeAi518Hwr8BFsrqjDG7AI2Ymu6ESJyMbaw8EIncXesXXVNT06XzjbgP8BvOzl+BbbJIoQv9v6qwf7hrg4kw7HeX2XYNspgc8yp+WGHuBOcm1+CrXbejRXFudjeQeOdcMHYP/pOZ/9xOvT+cokzxLEj0+XYh8B15phzaodj/wdYZ6drZ4ObsSWUCufaO8Y/DfuSrcR2X7zY5dzndnVmWyf39mInjkonzmku51bSs6PedNiecu7f3c79LHGOJbj8LhzrBN+NbX4qwDoTv9RNWjHYEvs9zr5gHYQPuoTJ5IuO+hOxJbKjwB9d8sf4ru5XhzR/6qRZgxXy3dg2/JQO4W7GNsWUY19iqS7nBJsfN2ObDA459/kKnB5cXdxXV0d9p3m0qzzdSXzd5rcOYb9wD51j5zu//XIn4SOwbfaHnO2PHOvGe1xcnfx+NrZ7eT3WZ+LanfZaYKvLfhbWIVzm3Ov/YGtf7edTnGM12Of/mx3Sug1b0KjCvhTDO5z/K133aJqG9e3VcvwzJ9ixKeXO9vk4FZcwb+J0YOgk7pOd/FGDbeY9ucOz0j5OpRiXcSouYXbgdNzo5Nwl2E4zVU6+cn2+E4GXnGs6iMs4FZf/tgI4s4u4v4WtMR91/pe0DvlopfO/7sRlnIrLf9VCH4ZOtHfF8zgi8jj2JXlXF+cNNqPlDYgBiqIoyqAT8NO0KIqiKIOHioqiKIriMQas+UtRFEUZemhNRVEURfEYId42oDuSkpJMZmamt81QFEXxG9atW1dqjEn2Vvo+LSqZmZmsXbvW22YoiqL4DSJyoOdQA4c2fymKoigeQ0VFURRF8RgqKoqiKIrHUFFRFEVRPIaKiqIoiuIxVFQURVEUj6GioiiKongMnx6novgGdU0tbCmsYlNBBeEhQUweHcvEkcOIiwz1tmmKF6ioa2LH4Wp2Hq6mtc0wMy2OaWPiiAj1xBJGir+joqJ0yQe7S/jD27vZcPAobZ1MEbdgbCI/XzKdiSO7WqpcCSS2FFZyzytbWXfg6HHngoOEnIwEbls8kfljh3vBOsVX8OkJJXNycoyOqB98thRWcu8bO/gwr5SU+EgunZPCzLR4ZqTG0dxq2Hm4is0FVTy2eh81DS3ceHIWt545gagwLaMEItUNzfx2xS6e/Hg/idFhfHVRFtPGxDJ5VCwikJtfQW5BBS+sK+RwVQNnTB7B/5wzmUmjtLDhDURknTHGnaWx3UtfRUVpxxjDox/t51fLtxMbEcItZ0zgugXphId03qxRVtPIvW/s4F/rCpg8ahj/vOlE4qK0SSyQKK1p5IqHPmZfWS3Xzc/gh2dP6vI/rm9q5fHV+/nLyjwamlv5+ZLpXD0vfZAtVgJCVETkHOB+7FK+fzfG3NtFuBOAT4ArjTHLeopXRWXwaGhu5cf/3syL6ws5e+pI7rtiJrERvROI93Ye4ZtPriM7NY5/3DifyDBtWw8Eqhuaufpvn5B3pIbHvzqPBb1s1iqvbeJ7/9zIql0lXLcgnbsvmEZYiPYJGiy8LSpu/9MiEgz8GTgXmApcLSJTuwj3f9g1oBUf4mhtE1f+9WNeXF/I98+ayEPXze21oACcPmkEv79yFusOHuWWZ9bT3No2gNYqg0FDcys3PbmOHYeqefC6ub0WFIDE6DAeu+EEvnnqWJ765CDXPfIp1Q3NA2it4kt4ovgwD8gzxuw1xjQBzwFLOgn3XeAF4IgH0lQ8RGVdM9c98inbD1fz1+vncutZEwgKkj7Hc372aH6+ZDrv7DjC3S9vGQBLlcHCGMN/L9vEx3vL+M3l2Zw+aUSf4wgOEu44dwr3XzWL9QeOcsNja6hpbBkAaxVfwxOikgLku+wXOMc+R0RSgIuBhzyQnuIhKuubuf7RT9ldXMPD18/lS9NGuRXf9QsyuPnUcTz7WT6rdpV4yEplsPnPlsO8mlvED8+eyMWzU92Ka8msFP509Ww25lfwtcfWUNekwhLoeEJUOivWdnTU/AH4H2NMa4+RidwkImtFZG1Jib6YBoraxhaWPvoZ2w9V8eB1czitH6XRzvj+4gmMTYrmJy9voaG5x79b8TGqG5r56atbmTo6lptPHeeROM+dMZo/XDmLtQfK+drjazRfBDieEJUCIM1lPxUo6hAmB3hORPYDlwF/EZGLOovMGPOwMSbHGJOTnOy1xcsCmtY2w63PbWBTQQV/unoOZ04Z6bG4w0OC+eXF0zlQVscD7+Z5LF5lcPjtil0cqW7kV5fMICTYc871L88cw2+vmMkne8u5fdkmfLnXqeIensg1a4AJIpIlImHAVcArrgGMMVnGmExjTCawDPi2MeYlD6St9INfLd/O29uP8NMLp3HOdPeavDpj4bgkLpmdwl9X7SHvSLXH41cGhk0FFTzx8X6uX5DBrLR4j8d/8exU/vtLk3glt4g/vL3b4/ErvoHbomKMaQFuwfbq2g48b4zZKiI3i8jN7saveJZ/fHKARz7cxw0LM/nKiZkDls6Pz59CVFgId720RUulfkBbm+HOf28hOSacH35p0oCl8+3TxnHZ3FTuf2c3L20oHLB0FO/hkSHQxpjlwPIOxzp1yhtjbvBEmkrfWZ1Xyk9f2coZk0fwkwuO6/XtUZJiwrlt8UTueWUrn+0r16k7fJz3dh5hc2El913e+/FJ/UFE+NXFM8gvr+P2ZZvIGB7F7PSEAUtPGXx0RNIQoaiinlue3UBWUjR/vHo2wf3oNtxXrjwhjeHRYTz4/p4BT0txjwdX7iElPpIls8YMeFphIUH89fq5jIwL51tPrae0pnHA01QGDxWVIUBjSyvfeno9TS1tPHTdXGLCB2eOrojQYL66KJOVO0vYVlQ1KGkqfWfN/nLWHjjKN07OItSDzvnuiI8K48Fr53K0rolbnllPiw6YDRhUVIYAP3t1G7n5Fdx3eTbjR8QMatrXL8gkOiyYv67S2oqv8tDKPSRGh3HlCYM7T9f0lDj+9+IZfLK3nN+8uXNQ01YGDhWVAOeFdQU88+lBbj51HOdMHz3o6cdFhXLN/HRezS3iYFndoKevdM/Ow9W8s+MIS0/M9MqcbZfNTeW6Ben8ddVe/rPl0KCnr3geFZUAZndxNXe9tIUFYxP54dkTvWbHjSeNJThI+NsHe71mg9I5f31/D1FhwXzlxAyv2XD3BdOYmRrHfy/bRH65Fjz8HRWVAKWuqYVvP72e6PBg/njVbI8OZOsro+IiuHh2Cs+vzaeyXicW9BWOVDfwSm4RV52QTkJ0mNfsCAsJ4oFr5gBwyzPW96f4LyoqAco9L28lr6SG3185ixGxEd42h2vnZ9DY0sbrm7SJw1d4eUMRLW2Gaxd4f82TtMQofnPZTHILKvn1G9u9bY7iBioqAcgL6wr417oCvnv6eE6e4BtT3WSnxjFhRAzL1uX3HFgZcIwxLFtXwOz0eMYlD27nja44Z/oovrook8c+2s9/thz2tjlKP1FRCTDyjtRw10tbmJeVyH+dOcHb5nyOiHDZ3FTWH6xgb0mNt80Z8mwprGJncTWXzXVvFmJPc8e5U8hOjeP2ZbnqX/FTVFQCiIbmVm55Zj2RYd73o3TGxbNTCBJ4YX2Bt00Z8rywvoCwkCAuyB74wY59ISwkiD9dPRtj4LvPbtAF3/wQ33rrKG7x89e2seNwNb+9Yiaj4rzvR+nIiNgITpmYzIvrC2lt0/nAvEVTSxsvb7TLRsdFDtyULP0lY3g0916azcb8Cu7T8St+h4pKgPDapiKe+fQg3zx1bL9W6hssLp2TyqHKBj7eU+ZtU4Ys7+44wtG6Zi71saYvV87PHv35+JX3duhisf6EikoAsK+0lh+9sJnZ6fH88OyBm2HWEyyeOpJhESHaBOZFlq0rYMSwcE4en+RtU7rlrvOnMmV0LN9/fiNFFfXeNkfpJSoqfk5Dcyvffno9IcHCn6+ZM2hzN/WXiNBgLpw5hje2HKJW1ywfdMprm1i58wgXz0nxOZ9bRyJCg/nLtXNobmnjlmfWq3/FT/DtXKX0yM9e3cb2Q1X8/opZjImP9LY5veLLM8fQ0Nym69h7gbe3F9PSZviyjznouyIryfpX1h+s0PnB/AQVFT/m5Y2FPPuZndfr9Mm+60fpSE5GAglRoazYVuxtU4YcK7YWkxIfybQxsd42pdd8eeYYrluQzsOr9vKW5hmfR0XFT9lxuIofvbCZeZnenderP4QEB3HmlJG8s71YmzQGkbqmFj7YXcLiqSMRGfj1dDzJXedPZUZKHLc9v5H9pbXeNkfpBhUVP6SqoZmb/7GOmIgQHrjG98aj9Iazp46kqqGFz/aVe9uUIcOqXaU0trRx9rSR3jalz7T7V4KDhJufWkd9U6u3TVK6YHBWaxpKtLVCcx0019utrcXZWkGCICjYbiEREBoJoVEQEt776NsMP3g+l4Kj9Tx70wKfmNerP5w8IZmI0CBWbD3MIh/vhRQorNh2mLjIUOZlJnrblH6RlhjF/VfN5obHPuPH/97M766Y2fsalzHQ2mSfzaY6aGkA02afS9MGQSHOsxlin8nQSLsFDf5yAP6OR0RFRM4B7geCgb8bY+7tcP5a4H+c3RrgW8aYXE+kPSi0tUFNMVQchKoCqCqCqkNQewRqS6C2FOoroKESmqr7Hn9wOEQmQGQ8RCXBsJEQMwpix0B8ut0SsyAijgff38Nb24q5+4KpnOCnLweAyLBgTpmQzIptxfz0wml+1xzjb7S0tvHO9iOcOWWEX9Zs2zl1YjK3nTWR3761i5mpcdywKAvqj8LR/fb5rDhon8/qw/aZrS2FhgobprWp7wmGx0JEHETEQ3QSRCdDzAj7bMaOgdgU+3zGjATNw4AHREVEgoE/A4uBAmCNiLxijNnmEmwfcKox5qiInAs8DMx3N22PU18BJTvsVpYHpXlQvgeOHoDWDutoh0bZzBWdbDPVqGwrCuGxEBZ9rBYSHHqshmLarEC1tdj4muuhqRYaq2ymrz9qH4KiDVBdDM1fbDtuDB/OCfXJPD1qAgvDToWDM2DEVIjwH6erK2dPG8WKbcVsKaxiRmqct80JaD7bX05lfTNnTx3lbVP6T0MlHN7Cd6K3kJ38PlFv5tG8qoTQxg5NqGEx9iUfMxKSJzkFtgQIH3bs2QwOP1Y7ETlWY2ltcloZ6uyz2VBl060/aguQ5Xuh5gi0dBg3ExIJCRmQOA6SxsPw8ZA82aYfMbTytidqKvOAPGPMXgAReQ5YAnwuKsaY1S7hPwG8O5S3rc2KxuFNcHiz3Y5sg2qXadmDw2H4OJspJn4JEjIhPsOWTGLH2IwykCUTY2wJq+IgHD3AkYM7+ODj1UwJK2ZKwypk+atOQIGkiZAyF1LmQPqJVmiCfL80eubkEQSJbZZRURlYVmwtJjwkiFMm+klTY1srFG+Bg59A4Tq7leUB1hF8SkQCW0LH8ErjbE5buJDh6VNs4S4uzRbuBpL2Z7OqCCoLnGd0v93K8iDvrS/WimJTYOQ0GDkdRs2A0TMhIcsvntH+4AlRSQFc5zMvoPtayI3AG12dFJGbgJsA0tM9sM6DMVCZDwVrbcYs2gCHNh1rpgoKhRGTYexptmQxYooVkrg077aninxewiobNplLXo2hKWwOr9xyEhIbDlWFcHgLHMqFovU2I+c+Y38bHgfpCyDrFBh7KoyY5pMZOCE6jHlZiazYWswPfHwmAH/GGMNb24o5eUIyUWE+6kZta7WFvL3vw/4P4OCnx57RmFG20DTzKhg9C0ZOQ4aNJv5oPb984EP+sjmMf5+yiNiIQZrHzOXZZOS0zq+l4gCU7IQj2+1WvBX2vGtbKcC2aIyeCWNmQ2qOvb7YlIBoQvNEDuvsLnQ6W6CInI4VlZO6iswY8zC2eYycnJy+zzrY1moFJP9TZ/vM+j7A1j5GZ9vMOWaW/VOTJkGI91a964mG5la++Y91lFQ38s9vnnhsosi4VLtNOsfuG2Mz8sFP4ODHsP8j2P2mPReVBOPOgAmLYdyZED3cOxfTCYunjuIXr23jYFkd6cOjvG1OQLLtUBWFFfXc6kNLIQC2GSnvbdj9Fux9zzYxgS3cZV9ha93pCyA+rdOfpyVG8eB1c7nu75/ynafX8+gNJ/jGjBJBwZA41m6Tzj12vKXRNq0fyoWijbaA++lDsNqp1QwbDWnzIG0+pM6zQuODhcGe8ISoFACu/3oqUNQxkIhkA38HzjXGDNxsgsbAPy6ybaIJWfZlmppjt5HTrY/DT2htM3zvuY2sPXCUB66Zzay0+K4Di9gmuoRMK5oAlYWwb5V9YPPehs3PA2Iz7eTzYNL5tv3Xi5w2KZlfvAardpdw3XDvrZMeyHywuxSAUyd5ecE2Y2zpfefrsGM5FK61x2NGwsRzYdzptnY9rPd+nwVjh/OrS2Zw+7JN/M8Lm/jt5X3oETbYhITbguzomTDnK/ZYS6NtcShcCwVrbEF428sQNRz+e4937e0nnhCVNcAEEckCCoGrgGtcA4hIOvAicL0xZpcH0uya4BC47gXrKIvxn1HmHTHG8IvXtvGfrYf5yQVT+7fuRVwKzLrabm1tcGgD7FphH+q37rbbiKkw9SKYusQ2Aw4yY5OiSYmP5MPdpVy3QEVlIPhwdymTRg5jpDe6nxtjm362vWRflqXO4z9mNpx+F0w8G0bOcKtEfkVOGocrG/jdW7sYExfJD7/kR02pIeGQOtdu879pj1Udsq0OviqOPeC2qBhjWkTkFuBNbJfiR40xW0XkZuf8Q8DdwHDgL04posUYk+Nu2l2SsXDAoh4sHnp/L4+v3s/XT8rixpOy3I8wKMhx5s+F0++wzsUdy+2DvvLXsPJX1vcy41KYfqmt8QwCIsJJ45NYvuUQLa1tft3d1RdpaG7ls/3lXD/Ygl22BzYvgy3LrJBIEGQsgnk3weTzbWcXD/LdM8ZzqLKeB97LY2RsONefmOnR+AeV2NF281M84rUzxiwHlnc49pDL968DX/dEWkOBJ1bv5//+s4MvzxzDj8+bMjCJxKfDgpvtVnUItr8CW16Ad35ut7QFtoYz9aIB701z8sQk/rk2n02FlcxJTxjQtIYan+0rp6mljZMmDEKvr7pym4dynzvWtJWxCObfDFMuhJiBa34TEX6xZDol1Y385OWtRIaF+NxSyUMFH+0KMnR59rOD3PPKVhZPHcnvrphJUNAgVIFjR9uq9/xv2jE5W5ZB7j/h1Vth+e22ZDn7OttDbgB6xC0al4QIfLCrVEXFw3yYV0pYcBDzswZooGxrC+x5Bzb8A3b+B9qare9y8c9tjTdu8F7sIcFBPHDNHL7x5FpuX5ZLaLCwZFbKoKWvWFRUfIgX1hXw439v5rRJyTxwzWzv9GRJyICTfwAn3WZ7p+Q+Zx38W1+0XR5nXWsFJsFzzSkJ0WHMSInjw7wSbj3Lx3oo+TmrdpUwNyPB812Jy/ZYIdn4LNQctj0M53/TdhIZNcOzafWBiNBgHr4+h6WPfcZtz+cSFhzEuTP8tynJH1FR8RH+8ckB7n55CwvHDeeh6+YSHuLlOYdE7GDKlDlw9i9g53LY8BSs+o3dxp0Oc5baWowHetSdND6Jh1ftpbqhmWGDNd4gwCmpbmTH4Wr+21OO65ZG2P4qrHvcjiWRYJhwNsy53n76SM/KyLBgHr3hBL7yyKfc8uwGftPcyiVztClssFBR8TLGGP6ycg+/eXMnZ00ZwQPXzCEi1McmsQsJh2kX260i34rLhqfgX0sheoStucxd6pZz/6QJSfxl5R4+2VvO4qn+N4uuL/JRnu1KfMoEN30ZZXtg3WOw8RmoK7MzS5xxF8y6zmcdyjHhITx543xuenIttz2fS1V9s50nTBlwVFS8SFub4ddvbOdvH+zjollj+M3lM31j8FZ3xKfZ3mOn3m7Hvqx9DD76A3z4ezu4MudG+9lH38vcjAQiQ4P50FnvQ3GfD3aXkhAV2r8FuVpbbO107SOwd6WtlUw+D+Z+Fcae7heD8mLCQ3j0hhP4r2c38NNXt1FR38ytZ07w3XEsAYKKipeobWzhe//cyFvbivnKiRn89MvTBscp7ymCgu2caBO/ZOc/WvcErH8Snr3STnEz9wY7wKuXY4XCQ4KZPzbx84F6insYY/hgdwkLxyf1LV9VFTn/5RN2LrzYVDueZM71fRqU6Cu0r8Nyx4ub+cPbu9lbUsv/uyzb91oDAggVFS9QcLSOrz+xll3F1dzz5ancsDDTv0tPcalwxp229rLjdVj7KLz7C1h5L0y90NZeMhb2OJjr5AnJ/GLnNgor6kmJjxwk4wOT3UdqOFLdyCm96UpsDOx7H9b83Y5dMm0w/kw4/3eOr8S/XxMhwUH8v8uyyUqO5jdv7uRAeR1/u36u365F5Ov4d27xQ97beYQfPJ9Lc2sbj391HqdM9PLUGZ4kOBSmXWS30t2w5hHbDr/lBUieAifcCNlXdjlV/6Lxdk6yT/aUcamOMXCLT/bamZAWjutGVOqP2t5bax+Fst0QmQgnfgdyvmbX7wkgRIRvnzae8ckxfO+fG7ngTx9y/1WzOXGc78yDFyj4fsNogNDU0sYvX9vGVx9bw4hh4bz0nUWBJSgdSZoA594LP9gBFz5gJ+1c/kP47WR49Xt2uYEOTBwxjLjIUF1i2AN8uq+cMXERpCZ0UuMrXA8vfQd+OwXevMPOtnvxX+G27banX4AJiitnTxvFC99aSExECNf8/RN+u2InLa1t3jYroNCayiCw/VAVty/bxObCSq5fkMGd508ZOm26YVG2PX72dfZltvYRyH3W9iZKPcGWiqddDKGRBAUJJ2Qm8tl+FRV3MMbw2b5yFo0bfqxZtbHGDmpd+6idJTc0CmZeaZsmR2d71+BBZsroWF695STueWUrf3o3j9V7yvi/S7MZPyLG26YFBCoqA0hDcyt/fGc3D6/aS1xkKA9dN5dzpvufs9MjiBybOO/sX1phWfsYvPQt+M+PIPsqmLuU+VmJvL29mCNVDdrm3U/2l9VRUt3IvKzhdgDruifsPFxN1XZ+t/Pus1PLD7EVCV2JDg/hvstnctL4JO5+eQvn3f8Bt5wxnptPHUdYiDbguIMY0/clSwaLnJwcs3btWm+b0WfaF0X69Rs72Fday6VzUrnr/CkkRPvuui1ewRg48JEVl+2vQGsTtcmz+UXRXE675JucM3eity30S15cvZn1rz/CXaPXEFG6xS51O+0i2x04bZ7fzn47UBypbuBnr27j9U2HmDAihjvPn8KpE5P9tvOMiKwb0Al7e0pfRcWzbDh4lF8v38Fn+8sZlxzNzy6cPjiT+fk7deWQ+xxm3RNI6Q6aJJyw7Etg1jWQcZJfjIvwKm2tdjzJxmdo3voKoaYJM3I6MvcGmHH5wC+xGwC8s72Yn726jYPldSwaP5w7zp3C9BT/q82pqHSDv4iKMYaP95bx4Mo9fLC7lKSYcG5bPJErclJ1Kve+Ygz3PPgk8yqWc76shsYqO1Yi+wq7jRigWZv9EWNsh4fN/4JNz9s5uCLiWda8kJ1jlnDnjVd520K/o6mljac/PcAf39nN0bpmzpoygptPHUdO5gBNyDkAqKh0g6+LSn1TK69vPsQ/Pt5PbkElSTHhfO2kTJaemEl0uLqr+ssD7+7mvhW72HjHScTnv20ntcx7B0zrsTVfpl0S0L2UuqU0z07wuXkZlO6EoBCY8CWYeRWFI05h0X0fcc+Xp/JVnZak31Q1NPPYh/t5fPU+jtY1k5ORwPUnZvClaaN8vpONt0VF33x9pK3NsP7gUV7eWMRLGwupbmhhbFI0/3vxdC6dk+rzGc4fmJdlxw6sKWxg8XRn0bCaI7D1JVsqb1/zZVS2XbFyypchaWLg+graV0/c8bpdVO3IVns8Y5GdGXjqRRDt3LMNhQDMG6ip7ocIsRGh3HrWBL5xShbPr8nnkY/2cetzG4mPCuXi2SksmZXCzNQ4v/W7DCRaU+kF9U129bz3dhzhjS2HKK5qJCwkiPOmj+KqeenMz0rUzOVBGppbyf7ZCpaemMGd5089PsDRA3a23G0vQ8Fn9lhCFkw6z847ln4ihPp5z7GmOjiwGnavgJ1vQOVBQOy1tQtp3PFrhdzx4mZe21TExrvPJtifpv3xcdraDKv3lPHcmoOs2FpMU2sbKfGRnDN9FKdPGkFOZoLPFCi9XVNRUemEqoZmcvMrWH+ggs/2l7Fm31GaWtsIDwnitEnJnDdjNGdMHqFTtA8gV/z1YxqbW3n5lpO6D1hZCLv+Y1+8+96H1ibb2ylzkV1ULPMkW6MZgMXFPEprCxzaCPs/tA73A6uhtdFey9jTYNK5MPEcGNb9ZJtn/nYlGcOjefSGEwbD6iFJZV0zb28v5o0th1i1q/Tzd8O8rETmZyUyJz2BmWnxXmsC97aoeOSqReQc4H7sGvV/N8bc2+G8OOfPA+qAG4wx6z2RtjvUNbWwv7SO/WW15B2pYcfhKnYcqmZfWS3G2NaUSSOH8ZUTMzh5YjLzMhOJDPPxl1OAMD8rkb+s3ENNYwsx3T2ccSl2+pcTbrQD/A58ZP0ve96BFXfZMOGxtittSo4dcJkyB6K83DxUUwJF66FgLRSssVtTjT2XPBlO+DqMO8POmRYW1asoS2sa2VNSy+U5aQNouBIXFcqlc1O5dG4qtY0tfLqvjA92l/Lh7lLuW7ELgCCBsckxTBo1jCmjhjF+RAyZSdFkDo/2mRrNQOG2qIhIMPBnYDFQAKwRkVeMMdtcgp0LTHC2+cCDzqfHMcZQXttERX0zFXVNVNQ1U1bTRElNI6U1jRyubKCosoGiinpKqhtdrgMyEqOYPCqWi2anMDs9nplp8cRqbcQrzMtK5E/v5rH+wNHeT2cTHnNs5mSwM+4eWG0XlMpfA3n/Bzg182FjYOQ0GDkVhk+A4eOt4z96hOe6L7e1Wl9Q+V4oy7PzaxVvg+ItUFNsw0iQ7XyQfaWtVWUs6rE20hVrnOltTvCjnkr+TnR4CGdMHskZk+1/VlnXzMaCCtYfOMr2Q1VsKqjg9U2HvvCbEcPCGRMfSUp8JCNjI0gaFkZSTDhJMWHERYaREBVKfFQYiX46rs0TNZV5QJ4xZi+AiDwHLAFcRWUJ8KSxbW2fiEi8iIw2xhw6Pjr3OfHX79LUyXw+MeEhjIgNJyU+ksmTRpCaEElWsi09ZCVFa48tH2J2egJBAuv6IiodiR0DMy6zG0BjtR1hfigXDm+x3XH3rrTrqrcTFGoXnho2BqKG2xpNZDyERls/TUiEFQKws/m2NEBzPTTX2Qka68rtQlZVh6C6CNpajsUdHAbJk2DcmTBqOoyeBWNmQVh0/66vA+sOHCU8JIgZfji2IlCIiwrl1InJnOqSZ2saW9hXUsu+slr2l9ZScLSOoooGth2qYuXOI9Q2tR4XT2J0GOt/sngwTfcYnniLpgD5LvsFHF8L6SxMCnCcqIjITcBNAOnp6X02RkT4+ZJpRIYFExdpFX94tC0JaNOV/xATHsLEkcNYf/Co5yINHwZZp9itndYWqMy3qxse3WfXhqkqsmuJHN1vm6jqK6Clvvu4QyLtxIxRifYz40SITbHNcwlZtiYUlzqgvp31B48yIyVOpxnxMWLCQ5iRGseM1M7Fvq6phdLqJspqG6mob6ayrpnWNt/1dfeEJ0Slsy4mHe9Ib8LYg8Y8DDwM1lHfH4Oumtd3MVJ8jzkZCbyaW0Rbmxm4BcyCQ2yzV09jXtqcWklLwxePh0Y6tRfv9rRqbGllS2EVNyzK9KodSt+JCgshfXgI6cN75zvzdTxRpCkAXD2DqUBRP8IoyheYk55AdUMLeSU13jbF+lnComxNxHULjfS6oABsLaqiqbWNOenx3jZFGeJ4QlTWABNEJEtEwoCrgFc6hHkF+IpYFgCVA+VPUQKH9hfk+gMebAILUNrv0Zz0BC9bogx13BYVY0wLcAvwJrAdeN4Ys1VEbhaRm51gy4G9QB7wN+Db7qarBD5ZSdEkRIV61q8SoGw4WEFKfKQuF6B4HY90dzLGLMcKh+uxh1y+G+A7nkhLGTqICLPTE1h/sMLbpvg86w8e9atJD5XARbuJKD7NnPR48o7UUFnX3HPgIUpRRT2HKhvUn6L4BCoqik/T7iPYkK9NYF3R3jyo/hTFF1BRUXyamWnxBAnaBNYN6w9UEBEaxNQxsd42RVFUVBTfJjo8hEmjYtmgzvouWX/wKNkp8YTqgnCKD6C5UPF55qTHs/FgBW1+PMp4oGhobmVrUSWzM+K9bYqiACoqih8wJz2B6sYWdh/xgUGQPsbWokqaW436UxSfQUVF8XnmZNgXpo5XOZ4Njq9ptvb8UnwEFRXF58kcHkVcZCibCiq8bYrPsTHfGfQ4TAc9Kr6Biori84gI2alxbMyv9LYpPsemgkpmpulU94rvoKKi+AWz0uLZVVxNfSdrTwxVymubOFhex8zUeG+boiifo6Ki+AUzU+NpbTNsLdLaSju5TnPgzLR4r9qhKK6oqCh+QbbTxLMxv8K7hvgQufkViMB0XelR8SFUVBS/YMSwCFLiI8kt0JpKO7n5FUwYEUOMLoOt+BAqKorfkJ0aR67WVAAwxlgnvfpTFB9DRUXxG2amxXOwvI7y2iZvm+J1Co7WU1bbpP4UxedQUVH8hvZSea6OVznmpNeaiuJjqKgofsOM1DhEYJOOVyE3v4KwkCAmjRrmbVMU5QuoqCh+Q0x4CBNGxGhNBcjNr2TamFjCQvQRVnwLzZGKXzEzNZ7c/ArsCtVDk5bWNjYXqpNe8U3cEhURSRSRt0Rkt/N53FSpIpImIu+JyHYR2Soit7qTpjK0yU6Lp6y2iYKj9d42xWvkldRQ39zKLHXSKz6IuzWVHwHvGGMmAO84+x1pAX5gjJkCLAC+IyJT3UxXGaLMckrnQ3kQZHu36uxUHfSo+B7uisoS4Ann+xPARR0DGGMOGWPWO9+rge1AipvpKkOUSaOGERYSxObCoeuszy2oZFhECJnDo71tiqIch7uiMtIYcwiseAAjugssIpnAbODTbsLcJCJrRWRtSUmJm+YpgUZYSBBTRscO6WnwNxdUkp0aR1CQeNsURTmOHkVFRN4WkS2dbEv6kpCIxAAvAN8zxlR1Fc4Y87AxJscYk5OcnNyXJJQhQnZKHFsKq4bk8sKNLa3sOFzFjJR4b5uiKJ3S46RBxpizujonIsUiMtoYc0hERgNHuggXihWUp40xL/bbWkXBjlf5xycH2FdWy7jkGG+bM6jsPFxNc6tRf4ris7jb/PUKsNT5vhR4uWMAERHgEWC7MeZ3bqanKJ+/UDcPwcklNznXPENnJlZ8FHdF5V5gsYjsBhY7+4jIGBFZ7oRZBFwPnCEiG53tPDfTVYYw45NjiAgN+vwFO5TYXFBJQlQoqQmR3jZFUTrFrTmzjTFlwJmdHC8CznO+fwioR1HxGCHBQUwbE8fmwgpvmzLobCqsZEZqPLYBQFF8Dx1Rr/glMxxnfesQctY3NLeyq7iabG36UnwYFRXFL8lOjaO+uZU9JTXeNmXQ2HbIiugMddIrPoyKiuKXtDvrh5JfZZOOpFf8ABUVxS/JSoohOiyYzUNoEOSmwkqSYsIZFRvhbVMUpUtUVBS/JDhImJYSx6YhNF1L+0h6ddIrvoyKiuK3ZKfEsa2oiubWNm+bMuDUNraQV1Kj41MUn0dFRfFbZqTG0djSxu7iwHfWby2qwhj1pyi+j4qK4re0L1I1FMartE+gqT2/FF9HRUXxWzKGRzEsIoTcIdADbHNhJaNiIxgxTJ30im+joqL4LSLiDIIcAqJSUKm1FMUvUFFR/JoZqXHsOFRNU0vgOuurG5rZW1qrI+kVv0BFRfFrZqTE0dTaxq7iam+bMmBsKbTLD03XmoriB6ioKH5NtrNYVSCPrG/viKDdiRV/QEVF8WvSEiOJiwwN6DXrNxdWMSYugqSYcG+boig9oqKi+DXtzvpA7la8uaBCnfSK36Ciovg9M1Lj2Hm4msaWVm+b4nEq65vZX1ZHtjMmR1F8HRUVxe+ZkRJHc6th5+HAc9ZvdZr1pqs/RfETVFQUv6fdgR2Izvr2CTPVSa/4C26JiogkishbIrLb+UzoJmywiGwQkdfcSVNROpKaEElCVGhADoLcXFhJakIkidFh3jZFUXqFuzWVHwHvGGMmAO84+11xK7DdzfQU5ThEhOkpcQFZU9lcUKm1FMWvcFdUlgBPON+fAC7qLJCIpALnA393Mz1F6ZTs1Dh2FVfT0Bw4zvqKuiYOltdpzy/Fr3BXVEYaYw4BOJ8jugj3B+B2oMe5NETkJhFZKyJrS0pK3DRPGSrMSImjpc2wI4Cc9e0j6bWmovgTPYqKiLwtIls62Zb0JgERuQA4YoxZ15vwxpiHjTE5xpic5OTk3vxEUZjRPg1+AC0vvElH0it+SEhPAYwxZ3V1TkSKRWS0MeaQiIwGjnQSbBFwoYicB0QAsSLylDHmun5brSgdGBMXwfDosIDyq2wuqCQtMZL4KHXSK/6Du81frwBLne9LgZc7BjDG3GGMSTXGZAJXAe+qoCieRkSYkRoXUNO1bCqo1EGPit/hrqjcCywWkd3AYmcfERkjIsvdNU5R+kJ2ajy7iqupa2rxtiluU1bTSGFFPTPVSa/4GT02f3WHMaYMOLOT40XAeZ0cXwmsdCdNRemK7JQ42gxsK6oiJzPR2+a4xbFBj/HeNURR+oiOqFcChmynVB8Iywtvyq9ERNekV/wPFRUlYBgRG8Go2Ag2BUAPsM2FFYxLjiEm3K3GBEUZdFRUlIAiOzWOzX5eUzHGkFtQqcsHK36JiooSUGSnxrG3tJbK+mZvm9JviqsaKalu/Lw5T1H8CRUVJaBo74K71Y+7Fuc6zXcztDux4oeoqCgBRSA46zcXVBISJEwbE+ttUxSlz6ioKAFFfFQY6YlRfu2szy2oYOLIYUSEBnvbFEXpMyoqSsCRneq/0+AbY9hcWKn+FMVvUVFRAo7s1DgKK+opq2n0til9Jr+8noq6Zp2eRfFbVFSUgKP9heyPtZV2J73WVBR/RUVFCTimp8Qh4p+isrmwkrCQICaNGuZtUxSlX6ioKAFHTHgI45JjPi/1+xO5+RVMHR1LaLA+mop/ojlXCUhmpcWzMb8CY4y3Tek1La1tbCqoZFZavLdNUZR+o6KiBCSz0uIpr20iv7ze26b0ml3FNdQ3tzI7Pd7bpihKv1FRUQKS9tL+hvyj3jWkD2zMrwDQmori16ioKAHJ5FHDiAgN+vxF7Q9szD9KYrQdvKko/oqKihKQhAQHMSMlzs9EpYKZqXGIiLdNUZR+o6KiBCyz0uLZWlRFU0ubt03pkeqGZnYfqWFWWoK3TVEUt3BLVEQkUUTeEpHdzmenT4SIxIvIMhHZISLbReREd9JVlN4wKy2BppY2th+q8rYpPbKpoBJjYJY66RU/x92ayo+Ad4wxE4B3nP3OuB/4jzFmMjAT2O5muorSI+0vaH9oAvvcSa/Tsyh+jruisgR4wvn+BHBRxwAiEgucAjwCYIxpMsZUuJmuovTImLgIkoeF+4WobDhYwdikaOKiQr1tiqK4hbuiMtIYcwjA+RzRSZixQAnwmIhsEJG/i0h0VxGKyE0islZE1paUlLhpnjKUEZHPB0H6MsYYNuZXaFdiJSDoUVRE5G0R2dLJtqSXaYQAc4AHjTGzgVq6bibDGPOwMSbHGJOTnJzcyyQUpXNmp8ezr7SWo7VN3jalSwor6imtadRBj0pAENJTAGPMWV2dE5FiERltjDkkIqOBI50EKwAKjDGfOvvL6EZUFMWTtJf+NxZUcPqkzirS3ufYoEft+aX4P+42f70CLHW+LwVe7hjAGHMYyBeRSc6hM4FtbqarKL0iOzUeEdh4sMLbpnTJhoMVhIcEMXm0zkys+D/uisq9wGIR2Q0sdvYRkTEistwl3HeBp0VkEzAL+JWb6SpKr4gJD2HiiGFs8GG/ysb8CqanxOnMxEpA0GPzV3cYY8qwNY+Ox4uA81z2NwI57qSlKP1lTkYCr20qorXNEBzkW6PVG5pb2VxQyQ2LMr1tiqJ4BC0aKQHPCZkJVDe0sKu42tumHMfmwkqaWtvIyVB/ihIYqKgoAc8JmYkArN1f7mVLjmeNY9NcFRUlQFBRUQKe1IRIRsaGs/aA702Dv27/UcYmRzM8JtzbpiiKR1BRUQIeESEnM5G1+31LVNraDGsPHOWEjERvm6IoHkNFRRkS5GQkUFhRT1GF76wEmVdSQ2V9MzmZ2vSlBA4qKsqQ4HO/ig81gbXXnNptU5RAQEVFGRJMHjWM6LBgn3LWr91fTlJMGBnDdaVHJXBQUVGGBCHBQczJSGCND/lV1hwoJycjUVd6VAIKFRVlyJCTkciOw1VUNTR72xSKqxrIL69Xf4oScKioKEOGEzITMMbOteVt1J+iBCoqKsqQYVZ6PMFB4hN+lTX7y4kMDWbqmFhvm6IoHkVFRRkyRIWFMG1MLJ/t876orD1Qzqy0eJ1EUgk4NEcrQ4r5WYlsyK+gobnVazZU1DWxtaiK+WO16UsJPFRUlCHFovFJNLW0eXV0/Sd7yzAGThqf5DUbFGWgUFFRhhTzshIJDRY+zCv1mg0f5pUSHRbMTF2TXglAVFSUIUVUWAiz0xJYvcd7orI6r4z5Y4erP0UJSDRXK0OOReOT2FxYSUVd06CnXVRRz97SWhaOGz7oaSvKYKCiogw5Fo0fjjHWtzHYfOQ0uy1Sf4oSoKioKEOOmWnxRIcFe8Wv8lFeKUkxYUwaOWzQ01aUwcAtURGRRBF5S0R2O5+dzjkhIt8Xka0iskVEnhWRCHfSVRR3CA0OYv7Y4azOG9yaijGGj/aUceK4JIKCdL4vJTBxt6byI+AdY8wE4B1n/wuISArwX0COMWY6EAxc5Wa6iuIWC8cNZ29p7aCur5J3pIaS6kZOGq/+FCVwcVdUlgBPON+fAC7qIlwIECkiIUAUUORmuoriFu0+jY8GsQmsvblt4Tj1pyiBi7uiMtIYcwjA+RzRMYAxphC4DzgIHAIqjTEruopQRG4SkbUisrakpMRN8xSlcyaNHEZSTBir9wxeE9hHeWVkDI8iLVHXT1EClx5FRUTednwhHbclvUnA8bMsAbKAMUC0iFzXVXhjzMPGmBxjTE5ycnJvr0NR+kRQkLBwXBIf7C6lrc0MeHpNLW18srdMaylKwNOjqBhjzjLGTO9kexkoFpHRAM7nkU6iOAvYZ4wpMcY0Ay8CCz15EYrSH86cMoLSmkY25FcMeFof7y2jprGFs6YcV5lXlIDC3eavV4ClzvelwMudhDkILBCRKLFL3J0JbHczXUVxm9MmjSAkSFix7fCAp7Vi62GiwoJ1fIoS8LgrKvcCi0VkN7DY2UdExojIcgBjzKfAMmA9sNlJ82E301UUt4mLDOXEccNZsbUYYwauCaytzfDWtmJOm5RMRGjwgKWjKL6AW6JijCkzxpxpjJngfJY7x4uMMee5hLvHGDPZaTa73hjT6K7hiuIJzp42in2ltewpqRmwNHILKjhS3cjZU0cNWBqK4ivoiHplSLN4ykgA3txaPGBpvLm1mJAg4fRJ6k9RAh8VFWVIMyougplp8azYOnB+lRXbDrNg7HDiokIHLA1F8RVUVJQhz5emjSS3oJJDlZ4fXZ93pIa9JbV8adpIj8etKL6Iiooy5Gn3dby9zfNNYO09y86aqqKiDA1UVJQhz/gRMYxNjh4Qv8qbW4uZmRrH6LhIj8etKL6IioqiAOdMG8XHe8s4UtXgsTj3l9aSm1/B2dO015cydFBRURTg8pw0WtsMz6/N91icz645SHCQcNncVI/FqSi+joqKogBZSdEsHDecZz/Lp9UDc4E1tbSxbG0BZ04ewchYXT5IGTqoqCiKwzXz0ymsqGfVbvdnx35z62HKapu4Zn66ByxTFP9BRUVRHM6eOoqkmDCe+fSg23E98+lBUhMiOWWCzrStDC1UVBTFISwkiMvmpvHujiMcruy/w35vSQ0f7y3j6nnpumywMuRQUVEUF66eZx32/1zTf4f9s58dJCRIuDxHHfTK0ENFRVFcyBgezckTkvjnmoM0tbT1+ff1Ta0sW1fA4qkjGTFMHfTK0ENFRVE68LWTsiiqbODJj/f3+bcPvb+Ho3XNfO2kLM8bpih+gIqKonTgtInJnDYpmT+8vZsj1b33reSX1/HQ+3u4IHs0J2QmDqCFiuK7qKgoSgdEhJ9cMJXGllZ+85+dvf7dr5ZvRwR+fN6UAbROUXwbFRVF6YRxyTF8bVEW/1pXwMZerGH/UV4pb2w5zHdOG8+YeJ3nSxm6qKgoShfccsZ4koeFc8/LW7p12jc0t/KzV7eSlhjJN04ZO4gWKorv4ZaoiMjlIrJVRNpEJKebcOeIyE4RyRORH7mTpqIMFsMiQrnr/CnkFlRyw2OfUVnffFyY8tomrv37p+wqruGeC6bpGvTKkMfdmsoW4BJgVVcBRCQY+DNwLjAVuFpEprqZrqIMCktmpXDf5TP5bF85lz24moKjdZ+f21dayyV/+YgthZX85do5umaKogAh7vzYGLMdrGOzG+YBecaYvU7Y54AlwDZ30laUweKyuamMiYvgm0+t49z7P2CUM0HkocoGwkKCeOYbC5ibkeBlKxXFN3BLVHpJCuA6PLkAmN9VYBG5CbgJID1dJ+NTfIOF45N48VsLeXDlHhpaWgHITo3nu2eMJzMp2svWKYrv0KOoiMjbQGerDN1pjHm5F2l0Vo3pcm5xY8zDwMMAOTk57s9BrigeYsLIYfzuylneNkNRfJoeRcUYc5abaRQAaS77qUCRm3EqiqIoPshgdCleA0wQkSwRCQOuAl4ZhHQVRVGUQcbdLsUXi0gBcCLwuoi86RwfIyLLAYwxLcAtwJvAduB5Y8xW98xWFEVRfBF3e3/9G/h3J8eLgPNc9pcDy91JS1EURfF9dES9oiiK4jFUVBRFURSPoaKiKIqieAwVFUVRFMVjiDG+O75QREqAA/38eRJQ6kFzPIXa1TfUrr6hdvWNQLQrwxiT7Elj+oJPi4o7iMhaY0yXMyd7C7Wrb6hdfUPt6htql+fR5i9FURTFY6ioKIqiKB4jkEXlYW8b0AVqV99Qu/qG2tU31C4PE7A+FUVRFGXwCeSaiqIoijLIqKgoiqIoHmNIiIqI/FBEjIgkedsWABH5hYhsEpGNIrJCRMZ42yYAEfmNiOxwbPu3iMR72yYAEblcRLaKSJuIeLWbpYicIyI7RSRPRH7kTVtcEZFHReSIiGzxti2uiEiaiLwnItud//BWb9sEICIRIvKZiOQ6dv3M2za1IyLBIrJBRF7zti39IeBFRUTSgMXAQW/b4sJvjDHZxphZwGvA3V62p523gOnGmGxgF3CHl+1pZwtwCbDKm0aISDDwZ+BcYCpwtYhM9aZNLjwOnONtIzqhBfiBMWYKsAD4jo/cs0bgDGPMTGAWcI6ILPCuSZ9zK3aZEL8k4EUF+D1wO90sYTzYGGOqXHaj8RHbjDErnPVvAD7BrtLpdYwx240xO71tBzAPyDPG7DXGNAHPAUu8bBMAxphVQLm37eiIMeaQMWa9870a+7JM8a5VYCw1zm6os3n9ORSRVOB84O/etqW/BLSoiMiFQKExJtfbtnRERP5XRPKBa/GdmoorXwPe8LYRPkYKkO+yX4APvCD9BRHJBGYDn3rZFODzZqaNwBHgLWOML9j1B2whuM3LdvQbtxbp8gVE5G1gVCen7gR+DJw9uBZZurPLGPOyMeZO4E4RuQO7MuY9vmCXE+ZObLPF04NhU2/t8gGkk2NeL936AyISA7wAfK9DTd1rGGNagVmO7/DfIjLdGOM1n5SIXAAcMcasE5HTvGWHu/i9qBhjzursuIjMALKAXBEB25SzXkTmGWMOe8uuTngGeJ1BEpWe7BKRpcAFwJlmEAcx9eF+eZMCIM1lPxUo8pItfoOIhGIF5WljzIvetqcjxpgKEVmJ9Ul5s6PDIuBCETkPiABiReQpY8x1XrSpzwRs85cxZrMxZoQxJtMYk4l9IcwZDEHpCRGZ4LJ7IbDDW7a4IiLnAP8DXGiMqfO2PT7IGmCCiGSJSBhwFfCKl23yacSW6B4Bthtjfudte9oRkeT23o0iEgmchZefQ2PMHcaYVOd9dRXwrr8JCgSwqPg494rIFhHZhG2e84lulsADwDDgLae780PeNghARC4WkQLgROB1EXnTG3Y4nRhuAd7EOpyfN8Zs9YYtHRGRZ4GPgUkiUiAiN3rbJodFwPXAGU6e2uiUxL3NaOA95xlcg/Wp+GUXXl9Dp2lRFEVRPIbWVBRFURSPoaKiKIqieAwVFUVRFMVjqKgoiqIoHkNFRVEURfEYKiqKoiiKx1BRURRFUTzG/wel4M67GW0KrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-4,4,100)\n",
    "sigma = 1 \n",
    "K_list = np.linspace(0.1,2,1000)\n",
    "error_list = [] \n",
    "\n",
    "for K in K_list:\n",
    "    LoG = (x**2/sigma**4 - 1/sigma**2)*np.exp(-x**2/(2*sigma**2))\n",
    "    DoG = np.exp(-x**2/(2*sigma**2)/(2*np.pi*sigma**2)) - np.exp(-x**2/(2*K**2*sigma**2)/(2*K**2*np.pi*sigma**2))\n",
    "    error_list.append(np.mean((LoG - DoG)**2) )\n",
    "\n",
    "    \n",
    "idx = np.argmin(error_list)\n",
    "opt_K = K_list[idx]\n",
    "DoG = np.exp(-x**2/(2*sigma**2)/(2*np.pi*sigma**2)) - np.exp(-x**2/(2*opt_K**2*sigma**2)/(2*opt_K**2*np.pi*sigma**2))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,LoG)\n",
    "plt.plot(x,DoG)\n",
    "plt.title('Approximation of LoG with DoG for a K of %s' %(opt_K) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p577tWgNgTFe"
   },
   "source": [
    "5.   What else is needed to improve the performance and isolate the road,  i.e. what else should be done? You don't have to provide any specific parameter or specific algorithm. Try to propose a direction which would be interesting to explore and how you would approach it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mpHhL9BFlq4"
   },
   "source": [
    "I would improve the resulting output image by applying a gamma correction to the output image, as currently the contrast of the image is quite low and it is difficult to distinguish between the output edges and the background. \n",
    "\n",
    "To isolate the road, I would apply the Difference of Gaussian kernel and fine tune the $\\sigma$ such that the high frequency components found in the vicinity of the trees are removed and more of the low frequency components in the roads are kept. This will reduce the amount of edge detections along the trees making the edges of the road become more isolated. Then I will apply a classification algorithm, which determines what value of a pixel intensity will most likely belong in the road, then I will use this pixel value as a threshold to binarize the image. Then I will perform an opening morphology to remove any noise, then I will apply the Hough transform to try to detect the line on the edges of the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sgm7JVhFubg"
   },
   "source": [
    "## 4.4 Foreground-background separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTmbkTFHh01"
   },
   "source": [
    "Foreground-background separation is an important task in the field of computer vision (see Figure). In this exercise, you will implement a simple unsupervised algorithm that leverages the variations in texture to segment the foreground object from the background. We will assume the foreground object has a distinct combination of textures compared to background. As mentioned earlier, Gabor filters are well-suited for texture analysis thanks to their frequency domain characteristics. Therefore, we will use a collection of Gabor filters with varying scale and orientations which we call a *filter bank*. The outline of the algorithm is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UScTstnoH8Yz"
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1w60xJ4UlG60Ie6ljRkHn0GJDdVu9eb5e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieFPLOKTImzD"
   },
   "source": [
    "**(Left)** Input image, **(Middle)** Foreground mask, **(Right)** Masked object. Foreground-Background separation aims at masking out the salient object pixels from the background pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cggieAGXBNp"
   },
   "source": [
    "---\n",
    "\n",
    "**Algorithm 1** Foreground-Background Segmentation Algorithm\n",
    "\n",
    "---\n",
    "\n",
    "**Input:** $x$ - input image\n",
    "\n",
    "**Output:** $y$ - pixelwise labels\n",
    "\n",
    "\n",
    "\n",
    "1.   Convert to grayscale if necessary.\n",
    "\n",
    ">>**if** $x$ is RGB **then**\n",
    "\n",
    ">>>$x$ $\\leftarrow$ rgb2gray($x$)\n",
    "\n",
    ">>**end if**\n",
    "\n",
    "2.   Create Gabor filterbank, $\\mathcal{F}_{gabor}$, with varying $\\sigma$, $\\lambda$ and $\\theta$.\n",
    "\n",
    "3.   Filter $x$ with the filterbank. Store each output in $fmaps$.\n",
    "\n",
    "4.   Compute the magnitude of the complex $fmaps$. Store the results in $fmags$.\n",
    "\n",
    ">>$fmags$ $\\leftarrow$  $\\vert fmaps \\vert$\n",
    "\n",
    "5.   Smooth $fmags$.\n",
    "\n",
    ">>$fmags$ $\\leftarrow$  smooth($fmags$)\n",
    "\n",
    "6.   Convert $fmags$ into data matrix, $f$.\n",
    "\n",
    ">>$f$ $\\leftarrow$  reshape($fmags$)\n",
    "\n",
    "7.   Cluster $f$ using kmeans into two sets.\n",
    "\n",
    ">>$y$ $\\leftarrow$  kmeans($f$, 2)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo-iPmhla2G9"
   },
   "source": [
    "### Questions (20 pts)\n",
    "\n",
    "1.   Run the algorithm on all test images with the provided parameter settings. What do you observe? Explain shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwYMD8qkdx5m"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG0G4XmldzDB"
   },
   "source": [
    "\n",
    "2.   Experiment with different $\\lambda$, $\\sigma$ and $\\theta$ settings until you get reasonable outputs. Report what parameter settings work better for each input image and try to explain why.\n",
    "\n",
    ">**Hint:** \n",
    "Don't change multiple variables at once. You might not need to change some at all.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMcXMskXdzFO"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NzeqBhJdzHv"
   },
   "source": [
    "3.   After you achieve good separation on all test images, run the script again with corresponding parameters but this time with\n",
    "\n",
    ">>>smoothingFlag = False\n",
    "\n",
    ">Describe what you observe at the output when smoothing is not applied on the magnitude images. Explain why it happens and try to reason about the motivation behind this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCyG914YcKcb"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiDCgYrlcL9r"
   },
   "source": [
    "###Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mR5GreUHcPtd"
   },
   "source": [
    "Please get yourself familiar with provided skeleton code **gabor_segmentation**.py. Keep in mind that you will need your implementation of the **createGabor** function.\n",
    "\n",
    "When you succesfully implement it all, it should run without problems and produce a reasonable segmentation with the default parameters on **kobi.png**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3f9_GNhvqH7"
   },
   "outputs": [],
   "source": [
    "image_id = \"Polar\"\n",
    "img = load_image(image_id) # load an image with the Polar bear\n",
    "\n",
    "show_image(img, f'Input image: {image_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abk-us2ZiR3k",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Control settings\n",
    "visFlag = False  # Set to true to visualize filter responses.\n",
    "smoothingFlag = True  # Set to true to postprocess filter outputs.\n",
    "\n",
    "# Design array of Gabor Filters\n",
    "# In this code section, you will create a Gabor Filterbank. A filterbank is\n",
    "# a collection of filters with varying properties (e.g. {shape, texture}).\n",
    "# A Gabor filterbank consists of Gabor filters of distinct orientations\n",
    "# and scales. We will use this bank to extract texture information from the\n",
    "# input image.\n",
    "\n",
    "numRows, numCols = img.shape\n",
    "\n",
    "# Estimate the minimum and maximum of the wavelengths for the sinusoidal\n",
    "# carriers.\n",
    "# ** This step is pretty much standard, therefore, you don't have to\n",
    "#    worry about it. It is cycles in pixels. **\n",
    "lambdaMin = 4/np.sqrt(2)\n",
    "lambdaMax = np.sqrt(abs(numRows)**2 + abs(numCols)**2)\n",
    "\n",
    "# Specify the carrier wavelengths.\n",
    "# (or the central frequency of the carrier signal, which is 1/lambda)\n",
    "n = np.floor(np.log2(lambdaMax/lambdaMin))\n",
    "lambdas = 2**np.arange(0, (n-2)+1) * lambdaMin\n",
    "\n",
    "# Define the set of orientations for the Gaussian envelope.\n",
    "dTheta = 2 * np.pi/8                  # \\\\ the step size\n",
    "orientations = np.arange(0, np.pi+dTheta, dTheta)\n",
    "\n",
    "# Define the set of sigmas for the Gaussian envelope. Sigma here defines\n",
    "# the standard deviation, or the spread of the Gaussian.\n",
    "sigmas = np.array([1, 2])\n",
    "\n",
    "# Now you can create the filterbank. We provide you with a Python list\n",
    "# called gaborFilterBank in which we will hold the filters and their\n",
    "# corresponding parameters such as sigma, lambda and etc.\n",
    "# ** All you need to do is to implement createGabor(). Rest will be handled\n",
    "#    by the provided code block. **\n",
    "gaborFilterBank = []\n",
    "tic = time.time()\n",
    "for lmbda in lambdas:\n",
    "    for sigma in sigmas:\n",
    "        for theta in orientations:\n",
    "            # Filter parameter configuration for this filter.\n",
    "            psi = 0\n",
    "            gamma = 0.5\n",
    "\n",
    "            # Create a Gabor filter with the specs above.\n",
    "            # (We also record the settings in which they are created. )\n",
    "            # // TODO: Implement the function createGabor() following\n",
    "            #          the guidelines in the given function template.\n",
    "            #          ** See createGabor.py for instructions ** //\n",
    "            filter_config = {}\n",
    "            filter_config[\"filterPairs\"] = createGabor(\n",
    "                sigma, theta, lmbda, psi, gamma)\n",
    "            filter_config[\"sigma\"] = sigma\n",
    "            filter_config[\"lmbda\"] = lmbda\n",
    "            filter_config[\"theta\"] = theta\n",
    "            filter_config[\"psi\"] = psi\n",
    "            filter_config[\"gamma\"] = gamma\n",
    "            gaborFilterBank.append(filter_config)\n",
    "ctime = time.time() - tic\n",
    "\n",
    "print('--------------------------------------\\n \\t\\tDetails\\n--------------------------------------')\n",
    "print(f'Total number of filters       : {len(gaborFilterBank)}')\n",
    "print(f'Number of scales (sigma)      : {len(sigmas)}')\n",
    "print(f'Number of orientations (theta): {len(orientations)}')\n",
    "print(f'Number of carriers (lambda)   : {len(lambdas)}')\n",
    "print(f'---------------------------------------')\n",
    "print(f'Filter bank created in {ctime} seconds.')\n",
    "print(f'---------------------------------------')\n",
    "\n",
    "# Filter images using Gabor filter bank using quadrature pairs (real and imaginary parts)\n",
    "# You will now filter the input image with each complex Gabor filter in\n",
    "# gaborFilterBank structure and store the output in the cell called\n",
    "# featureMaps.\n",
    "# // Hint-1: Apply both the real imaginary parts of each kernel\n",
    "#            separately in the spatial domain (i.e. over the image). //\n",
    "# // Hint-2: Assign each output (i.e. real and imaginary parts) in\n",
    "#            variables called real_out and imag_out. //\n",
    "# // Hint-3: Use built-in cv2 function, filter2D, to convolve the filter\n",
    "#            with the input image. Check the options for padding. Find\n",
    "#            the one that works well. You might want to\n",
    "#            explain what works better and why shortly in the report.\n",
    "featureMaps = []\n",
    "\n",
    "for gaborFilter in gaborFilterBank:\n",
    "    # gaborFilter[\"filterPairs\"] has two elements. One is related to the real part\n",
    "    # of the Gabor Filter and the other one is the imagineray part.\n",
    "    real_out = cv2.filter2D(img, -1, np.ascontiguousarray(gaborFilter['filterPairs'][:, :, 0]), borderType=cv2.BORDER_REFLECT)  # \\\\TODO: filter the grayscale input with real part of the Gabor\n",
    "    imag_out = cv2.filter2D(img, -1, np.ascontiguousarray(gaborFilter['filterPairs'][:, :, 1]), borderType=cv2.BORDER_REFLECT)  # \\\\TODO: filter the grayscale input with imaginary part of the Gabor\n",
    "    featureMaps.append(np.stack((real_out, imag_out), 2))\n",
    "    \n",
    "    # Visualize the filter responses if you wish.\n",
    "    if visFlag:\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        ax.imshow(real_out)    # Real\n",
    "        title = \"Re[h(x,y)], \\n lambda = {0:.4f}, \\n theta = {1:.4f}, \\n sigma = {2:.4f}\".format(\n",
    "            gaborFilter[\"lmbda\"], gaborFilter[\"theta\"], gaborFilter[\"sigma\"])\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.imshow(imag_out)    # Real\n",
    "        title = \"Im[h(x,y)], \\n lambda = {0:.4f}, \\n theta = {1:.4f}, \\n sigma = {2:.4f}\".format(\n",
    "            gaborFilter[\"lmbda\"], gaborFilter[\"theta\"], gaborFilter[\"sigma\"])\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Compute the magnitude\n",
    "# Now, you will compute the magnitude of the output responses.\n",
    "# \\\\ Hint: (real_part^2 + imaginary_part^2)^(1/2) \\\\\n",
    "featureMags = []\n",
    "for i, fm in enumerate(featureMaps):\n",
    "    real_part = fm[..., 0]\n",
    "    imag_part = fm[..., 1]\n",
    "    mag = (real_part**2 + imag_part**2)**(1/2)  # \\\\TODO: Compute the magnitude here\n",
    "    featureMags.append(mag)\n",
    "\n",
    "    # Visualize the magnitude response if you wish.\n",
    "    if visFlag:\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.imshow(mag.astype(np.uint8))    # visualize magnitude\n",
    "        title = \"Re[h(x,y)], \\n lambda = {0:.4f}, \\n theta = {1:.4f}, \\n sigma = {2:.4f}\".format(gaborFilterBank[i][\"lmbda\"],\n",
    "                                                                                                 gaborFilterBank[i][\"theta\"],\n",
    "                                                                                                 gaborFilterBank[i][\"sigma\"])\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "# Prepare and Preprocess features\n",
    "# You can think of each filter response as a sort of feature representation\n",
    "# for the pixels. Now that you have numFilters = |gaborFilterBank| filters,\n",
    "# we can represent each pixel by this many features.\n",
    "# \\\\ Q: What kind of features do you think gabor filters might correspond to?\n",
    "\n",
    "# You will now implement a smoothing operation over the magnitude images in\n",
    "# featureMags.\n",
    "# \\\\ Hint: For each i in [1, length(featureMags)], smooth featureMags{i}\n",
    "#          using an appropriate first order Gaussian kernel.\n",
    "# \\\\ Hint: cv2 filter2D function is helpful here.\n",
    "features = np.zeros(shape=(numRows, numCols, len(featureMags)))\n",
    "if smoothingFlag:\n",
    "    # \\\\TODO:\n",
    "    # FOR_LOOP\n",
    "    for i, fmag in enumerate(featureMags):\n",
    "        features[:, :, i] = cv2.Sobel(fmag, cv2.CV_64F, 1, 0,ksize=3)\n",
    "    # i)  filter the magnitude response with appropriate Gaussian kernels\n",
    "    # ii) insert the smoothed image into features[:,:,j]\n",
    "    # END_FOR\n",
    "else:\n",
    "    # Don't smooth but just insert magnitude images into the matrix\n",
    "    # called features.\n",
    "    for i, fmag in enumerate(featureMags):\n",
    "        features[:, :, i] = fmag\n",
    "\n",
    "\n",
    "# Reshape the filter outputs (i.e. tensor called features) of size\n",
    "# [numRows, numCols, numFilters] into a matrix of size [numRows*numCols, numFilters]\n",
    "# This will constitute our data matrix which represents each pixel in the\n",
    "# input image with numFilters features.\n",
    "features = np.reshape(features, newshape=(numRows * numCols, -1))\n",
    "\n",
    "\n",
    "# Standardize features.\n",
    "# \\\\ Hint: see http://ufldl.stanford.edu/wiki/index.php/Data_Preprocessing for more information.\n",
    "\n",
    "# \\\\ TODO: i)  Implement standardization on matrix called features.\n",
    "features = sklearn.preprocessing.scale(features)\n",
    "#          ii) Return the standardized data matrix.\n",
    "\n",
    "\n",
    "# (Optional) Visualize the saliency map using the first principal component\n",
    "# of the features matrix. It will be useful to diagnose possible problems\n",
    "# with the pipeline and filterbank.\n",
    "\n",
    "transformed_feature = PCA(n_components=1).fit_transform(\n",
    "    features)  # select the first component\n",
    "transformed_feature = np.ascontiguousarray(\n",
    "    transformed_feature, dtype=np.float32)\n",
    "feature2DImage = np.reshape(transformed_feature, newshape=(numRows, numCols))\n",
    "plt.figure()\n",
    "plt.title(f'Pixel representation projected onto first PC')\n",
    "plt.imshow(feature2DImage, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Apply k-means algorithm to cluster pixels using the data matrix,\n",
    "# features.\n",
    "# \\\\ Hint-1: search about sklearn kmeans function https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html.\n",
    "# \\\\ Hint-2: use the parameter k defined in the first section when calling\n",
    "#            sklearn's built-in kmeans function.\n",
    "tic = time.time()\n",
    "pixLabels = KMeans(n_clusters=2).fit_predict(features)  # \\\\TODO: Return cluster labels per pixel\n",
    "ctime = time.time() - tic\n",
    "print(f'Clustering completed in {ctime} seconds.')\n",
    "\n",
    "\n",
    "# Visualize the clustering by reshaping pixLabels into original grayscale\n",
    "# input size [numRows numCols].\n",
    "pixLabels = np.reshape(pixLabels, newshape=(numRows, numCols))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Pixel clusters')\n",
    "plt.imshow(pixLabels)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Use the pixLabels to visualize segmentation.\n",
    "Aseg1 = np.zeros_like(img)\n",
    "Aseg2 = np.zeros_like(img)\n",
    "# check for the value of your labels in pixLabels (could be 1 or 0 instead of 2)\n",
    "BW = pixLabels == 1\n",
    "# do this only if you have 3 channels in the img\n",
    "# BW = np.repeat(BW[:, :, np.newaxis], 3, axis=2)\n",
    "Aseg1[BW] = img[BW]\n",
    "Aseg2[~BW] = img[~BW]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'montage')\n",
    "plt.imshow(Aseg1, 'gray', interpolation='none')\n",
    "plt.imshow(Aseg2, 'jet',  interpolation='none', alpha=0.7)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1oBHyce1saAI",
    "V2NtMMr9RSVv",
    "RkT7BklaTUmj",
    "762bvpRYTual",
    "-2ZB6tEeV_Ls",
    "ViVNlHPOa2Jd",
    "eMgRkSaSa-7u",
    "H1mP6EytbZE2",
    "a2fL29EAbaYt",
    "32eQTHQobdGG",
    "WIpIVPE4tvE9",
    "38iQckSqkLjC"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
